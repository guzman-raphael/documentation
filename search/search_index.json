{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"core/","text":"Core \u00b6 DataJoint Core projects are fully open-source and are built to develop, define, manage, and visualize data pipelines . Below are the projects that make up the family of core open-source projects. API s \u00b6 DataJoint Python A low-level client for managing data pipelines . Getting started DataJoint MATLAB A low-level client for managing data pipelines . Getting started Pharus Expose data pipelines via a REST interface. Getting started Web GUI s \u00b6 LabBook Data entry and data model browsing for data pipelines . Getting started SciViz A visualization framework for making low-code web apps for data pipelines . Getting started Container Images \u00b6 graph datajoint/mysql; datajoint/miniconda3 --> datajoint/djbase; datajoint/djbase --> datajoint/djtest; datajoint/djbase --> datajoint/datajoint; datajoint/djbase --> datajoint/djlab; datajoint/djlab --> datajoint/djlabhub; datajoint/mysql An optimized, MySQL backend for data pipelines . Getting started datajoint/miniconda3 A minimal Python image with conda . Getting started datajoint/djbase Adds only dependencies for managing data pipelines . Getting started datajoint/djtest Adds testing tools like pytest . Getting started datajoint/datajoint Official image for managing data pipelines . Getting started datajoint/djlab Adds a local Jupyter Lab environment. Getting started datajoint/djlabhub Adds a client to allow hosting with Jupyter Hub . Getting started","title":"Core"},{"location":"core/#core","text":"DataJoint Core projects are fully open-source and are built to develop, define, manage, and visualize data pipelines . Below are the projects that make up the family of core open-source projects.","title":"Core"},{"location":"core/#apis","text":"DataJoint Python A low-level client for managing data pipelines . Getting started DataJoint MATLAB A low-level client for managing data pipelines . Getting started Pharus Expose data pipelines via a REST interface. Getting started","title":"APIs"},{"location":"core/#web-guis","text":"LabBook Data entry and data model browsing for data pipelines . Getting started SciViz A visualization framework for making low-code web apps for data pipelines . Getting started","title":"Web GUIs"},{"location":"core/#container-images","text":"graph datajoint/mysql; datajoint/miniconda3 --> datajoint/djbase; datajoint/djbase --> datajoint/djtest; datajoint/djbase --> datajoint/datajoint; datajoint/djbase --> datajoint/djlab; datajoint/djlab --> datajoint/djlabhub; datajoint/mysql An optimized, MySQL backend for data pipelines . Getting started datajoint/miniconda3 A minimal Python image with conda . Getting started datajoint/djbase Adds only dependencies for managing data pipelines . Getting started datajoint/djtest Adds testing tools like pytest . Getting started datajoint/datajoint Official image for managing data pipelines . Getting started datajoint/djlab Adds a local Jupyter Lab environment. Getting started datajoint/djlabhub Adds a client to allow hosting with Jupyter Hub . Getting started","title":"Container Images"},{"location":"glossary/","text":"Glossary \u00b6 There are many terms that are reused throughout the documentation that we feel important to define together. We've taken careful consideration to be consistent. Below you will find how we've understood and use these terms. Term Definition data pipeline formal definition of a directed acyclic graph (DAG) of processes that achieves the DataJoint Mantra workflow a formal representation of the steps for executing an experiment from data collection to analysis. Also the software configured for performing these steps. A typical workflow is composed of tables with inter-dependencies and processes to compute and insert data into the tables. DataJoint a software framework for database programming directly from matlab and python. Thanks to its support of automated computational dependencies, DataJoint serves as a workflow management system. DataJoint pipeline the data schemas and transformations underlying a DataJoint workflow. DataJoint allows defining code that specifies both the workflow and the data pipeline, and we have used the words \"pipeline\" and \"workflow\" almost interchangeably. DataJoint schema a software module implementing a portion of an experiment workflow. Includes database table definitions, dependencies, and associated computations. DataJoint Elements software modules implementing portions of experiment workflows designed for ease of integration into diverse custom workflows. djHub our team's internal platform for delivering cloud-based infrastructure to support online training resources, validation studies, and collaborative projects.","title":"Glossary"},{"location":"glossary/#glossary","text":"There are many terms that are reused throughout the documentation that we feel important to define together. We've taken careful consideration to be consistent. Below you will find how we've understood and use these terms. Term Definition data pipeline formal definition of a directed acyclic graph (DAG) of processes that achieves the DataJoint Mantra workflow a formal representation of the steps for executing an experiment from data collection to analysis. Also the software configured for performing these steps. A typical workflow is composed of tables with inter-dependencies and processes to compute and insert data into the tables. DataJoint a software framework for database programming directly from matlab and python. Thanks to its support of automated computational dependencies, DataJoint serves as a workflow management system. DataJoint pipeline the data schemas and transformations underlying a DataJoint workflow. DataJoint allows defining code that specifies both the workflow and the data pipeline, and we have used the words \"pipeline\" and \"workflow\" almost interchangeably. DataJoint schema a software module implementing a portion of an experiment workflow. Includes database table definitions, dependencies, and associated computations. DataJoint Elements software modules implementing portions of experiment workflows designed for ease of integration into diverse custom workflows. djHub our team's internal platform for delivering cloud-based infrastructure to support online training resources, validation studies, and collaborative projects.","title":"Glossary"},{"location":"projects/","text":"Projects \u00b6 DataJoint was originally developed by working systems neuroscientists at Baylor College of Medicine to meet the needs of their own research. Below is a partial list of known teams who use DataJoint. Please let us know if you would like to add another group or make other corrections by sending an email to support@datajoint.com. Multi-lab collaboratives \u00b6 International Brain Lab ( GitHub ) Mesoscale Activity Project MICrONS Sainsbury Wellcome Centre Aeon U19 Projects NYU Osmonauts Harvard DOPE Columbia MoC3 Princeton BRAIN CoGS ( GitHub ) Rochester-NYU-Harvard Neural basis of causal inference Individual Labs \u00b6 Allen Institute Mindscope Program Karel Svoboda Lab Forrest Collman Arizona State University Rick Gerkin Lab Baylor College of Medicine Nuo Li Lab Matthew McGinley Lab Paul Pfaffinger Lab Jacob Reimer Lab Andreas Tolias Lab Boston University Jerry Chen Lab Benjamin Scott Lab California Institute of Technology Siapas Lab Cold Spring Harbor Laboratory Engel Lab Columbia University's Zuckerman Institute Mark Churchland Lab Elizabeth Hillman Lab Rui Costa Lab EPFL Mackenzie Mathis Lab FORTH Emmanouil Froudarakis Lab ( GitHub ) Harvard Medical School Jan Drugowitsch Lab Harvey Lab Sabatini Lab Stelios Smirnakis Lab Indiana University Lu Lab Johns Hopkins University Applied Physics Lab ( GitHub ) Kavli Institute for Systems Neuroscience Moser Group Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen Busse Lab Katzner Lab MIT Fan Wang Lab National Institute of Environmental Health Sciences Eric E. Thomson New York University Dora Angelaki Lab Northwestern University James Cotton Lab ( GitHub ) Lucas Pinto Lab Princeton University Carlos Brody Lab David Tank Lab Ilana Witten Lab Jonathan Pillow Lab Seung Lab Sainsbury Wellcome Centre Tiago Branco Lab ( GitHub ) Stanford University Karl Deisseroth Lab Shaul Druckmann Lab Tel-Aviv University Pablo Blinder Lab ( GitHub ) University of Bonn Tobias Rose Lab University of California, Los Angeles Anne Churchland Lab University of California, San Diego David Kleinfeld Lab ( GitHub ) University of California, San Francisco Loren Frank Lab University of Oregon Santiago Jaramillo Lab ( GitHub ) Michael Wehr Lab ( GitHub ) University of Rochester Greg DeAngelis Lab Ralf Haefner Lab University of Washington Edgar Y. Walker Lab Tuthill Lab Wilhelm Schickard Institute for Computer Science Sinz Lab Berens Lab Euler Lab Bethge Lab ... and more labs","title":"Projects"},{"location":"projects/#projects","text":"DataJoint was originally developed by working systems neuroscientists at Baylor College of Medicine to meet the needs of their own research. Below is a partial list of known teams who use DataJoint. Please let us know if you would like to add another group or make other corrections by sending an email to support@datajoint.com.","title":"Projects "},{"location":"projects/#multi-lab-collaboratives","text":"International Brain Lab ( GitHub ) Mesoscale Activity Project MICrONS Sainsbury Wellcome Centre Aeon U19 Projects NYU Osmonauts Harvard DOPE Columbia MoC3 Princeton BRAIN CoGS ( GitHub ) Rochester-NYU-Harvard Neural basis of causal inference","title":"Multi-lab collaboratives "},{"location":"projects/#individual-labs","text":"Allen Institute Mindscope Program Karel Svoboda Lab Forrest Collman Arizona State University Rick Gerkin Lab Baylor College of Medicine Nuo Li Lab Matthew McGinley Lab Paul Pfaffinger Lab Jacob Reimer Lab Andreas Tolias Lab Boston University Jerry Chen Lab Benjamin Scott Lab California Institute of Technology Siapas Lab Cold Spring Harbor Laboratory Engel Lab Columbia University's Zuckerman Institute Mark Churchland Lab Elizabeth Hillman Lab Rui Costa Lab EPFL Mackenzie Mathis Lab FORTH Emmanouil Froudarakis Lab ( GitHub ) Harvard Medical School Jan Drugowitsch Lab Harvey Lab Sabatini Lab Stelios Smirnakis Lab Indiana University Lu Lab Johns Hopkins University Applied Physics Lab ( GitHub ) Kavli Institute for Systems Neuroscience Moser Group Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen Busse Lab Katzner Lab MIT Fan Wang Lab National Institute of Environmental Health Sciences Eric E. Thomson New York University Dora Angelaki Lab Northwestern University James Cotton Lab ( GitHub ) Lucas Pinto Lab Princeton University Carlos Brody Lab David Tank Lab Ilana Witten Lab Jonathan Pillow Lab Seung Lab Sainsbury Wellcome Centre Tiago Branco Lab ( GitHub ) Stanford University Karl Deisseroth Lab Shaul Druckmann Lab Tel-Aviv University Pablo Blinder Lab ( GitHub ) University of Bonn Tobias Rose Lab University of California, Los Angeles Anne Churchland Lab University of California, San Diego David Kleinfeld Lab ( GitHub ) University of California, San Francisco Loren Frank Lab University of Oregon Santiago Jaramillo Lab ( GitHub ) Michael Wehr Lab ( GitHub ) University of Rochester Greg DeAngelis Lab Ralf Haefner Lab University of Washington Edgar Y. Walker Lab Tuthill Lab Wilhelm Schickard Institute for Computer Science Sinz Lab Berens Lab Euler Lab Bethge Lab ... and more labs","title":"Individual Labs "},{"location":"publications/","text":"Publications \u00b6 The following publications relied on DataJoint open-source software for data analysis. If you would like make additions or corrections, please send an email to support@datajoint.com. If your work uses DataJoint or DataJoint Elements, please cite the following: DataJoint Yatsenko D, Reimer J, Ecker AS, Walker EY, Sinz F, Berens P, Hoenselaar A, Cotton RJ, Siapas AS, Tolias AS. DataJoint: managing big scientific data using MATLAB or Python . bioRxiv. 2015 Jan 1:031658. Yatsenko D, Walker EY, Tolias AS. DataJoint: a simpler relational data model . arXiv:1807.11104. 2018 Jul 29. DataJoint Elements Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D, Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for Neurophysiology . bioRxiv. 2021 Jan 1. 2022 \u00b6 Wang, Y., Chiola, S., Yang, G., Russell, C., Armstrong, C. J., Wu, Y., ... & Shcheglovitov, A. (2022). Modeling human telencephalic development and autism-associated SHANK3 deficiency using organoids generated from single neural rosettes . Nature Communications , 13(1), 1-25. Franke, K., Willeke, K. F., Ponder, K., Galdamez, M., Zhou, N., Muhammad, T., ... & Tolias, A. S. (2022). State-dependent pupil dilation rapidly shifts visual feature selectivity . Nature , 1-7. Pettit, N. H., Yap, E., Greenberg, M. E., Harvey, C. D. (2022). Fos ensembles encode and shape stable spatial maps in the hippocampus . Nature . Saunders, J. L., Ott, L. A., Wehr, M. (2022). AUTOPILOT: Automating experiments with lots of Raspberry Pis . bioRxiv . Born, G. (2022). The effect of feedback on sensory processing in the mouse early visual system . Doctoral dissertation . Cadena, S. A., Willeke, K. F., Restivo, K., Denfield, G., Sinz, F. H., Bethge, M., ... & Ecker, A. S. (2022). Diverse task-driven modeling of macaque V4 reveals functional specialization towards semantic tasks. . bioRxiv . Cotton, R. J. (2022). PosePipe: Open-Source Human Pose Estimation Pipeline for Clinical Research . arXiv . 2203.08792. Cotton, R. J., McClerklin, E., Cimorelli, A., & Patel, A. (2022). Spatiotemporal characterization of gait from monocular videos with transformers . Cotton, R. J., McClerklin, E., Cimorelli, A., Patel, A., & Karakostas, T. (2022). Transforming Gait: Video-Based Spatiotemporal Gait Analysis . arXiv . 2203.09371. Fu, J., Willeke, K. F., Pierzchlewicz, P. A., Muhammad, T., Denfield, G. H., Sinz, F. H., & Tolias, A. S. (2022). Heterogeneous Orientation Tuning Across Sub-Regions of Receptive Fields of V1 Neurons in Mice . Available at SSRN 4029075 . Goetz, J., Jessen, Z. F., Jacobi, A., Mani, A., Cooler, S., Greer, D., ... & Schwartz, G. W. (2022). Unified classification of mouse retinal ganglion cells using function, morphology, and gene expression . Cell reports , 40(2), 111040. Jaffe, A. (2022). Optical investigation of microcircuit computations in mouse primary visual cortex . Doctoral dissertation . Obenhaus, H.A., Zong, W., Jacobsen, R.I., Rose, T., Donato, F., Chen, L., Cheng, H., Bonhoeffer, T., Moser, M.B. & Moser, E.I. (2022). Functional network topography of the medial entorhinal cortex . Proceedings of the National Academy of Sciences , 119 (7). Roukes, M. L. (2022, May). The Integrated Neurophotonics Paradigm . In CLEO: Applications and Technology (pp. ATh4I-6). Optica Publishing Group. Sanchez, M., Moore, D., Johnson, E. C., Wester, B., Lichtman, J. W., & Gray-Roncal, W. (2022). Connectomics Annotation Metadata Standardization for Increased Accessibility and Queryability . Frontiers in Neuroinformatics . Spacek, M. A., Crombie, D., Bauer, Y., Born, G., Liu, X., Katzner, S., & Busse, L. (2022). Robust effects of corticothalamic feedback and behavioral state on movie responses in mouse dLGN . Elife , 11, e70469. Tseng, S. Y., Chettih, S. N., Arlt, C., Barroso-Luque, R., & Harvey, C. D. (2022). Shared and specialized coding across posterior cortical areas for dynamic navigation decisions. . Neuron . Turner, N. L., Macrina, T., Bae, J. A., Yang, R., Wilson, A. M., Schneider-Mizell, C., ... & Seung, H. S. (2022). Reconstruction of neocortex: Organelles, compartments, cells, circuits, and activity. . Cell, 185 (6), 1082-1100. Ustyuzhaninov, I., Burg, M.F., Cadena, S.A., Fu, J., Muhammad, T., Ponder, K., Froudarakis, E., Ding, Z., Bethge, M., Tolias, A. & Ecker, A.S. (2022). Digital twin reveals combinatorial code of non-linear computations in the mouse primary visual cortex . bioRxiv . Willeke, K. F., Fahey, P. G., Bashiri, M., Pede, L., Burg, M. F., Blessing, C., ... & Sinz, F. H. (2022). The Sensorium competition on predicting large-scale mouse primary visual cortex activity . arXiv preprint arXiv:2206.08666 . 2021 \u00b6 Bae, J. A., Baptiste, M., Bodor, A. L., Brittain, D., Buchanan, J., Bumbarger, D. J., Castro, M. A., Celii, B., Cobos, E., Collman, F.others. (2021). Functional connectomics spanning multiple areas of mouse visual cortex . bioRxiv . Born, G., Schneider-Soupiadis, F. A., Erisken, S., Vaiceliunaite, A., Lao, C. L., Mobarhan, M. H., Spacek, M. A., Einevoll, G. T., & Busse, L. (2021). Corticothalamic feedback sculpts visual spatial integration in mouse thalamus . Nature Neuroscience , 24 (12), 1711\u20131720. Burg, M. F., Cadena, S. A., Denfield, G. H., Walker, E. Y., Tolias, A. S., Bethge, M., & Ecker, A. S. (2021). Learning divisive normalization in primary visual cortex . PLOS Computational Biology , 17 (6), e1009028. Claudi, F., Campagner, D., & Branco, T. (2021). Innate heuristics and fast learning support escape route selection in mice . bioRxiv . Cohrs, K.H. (2021). Investigation of feedback mechanisms in visual cortex using deep learning models [Master\u2019s thesis]. University of G\u00f6ttingen. Finkelstein, A., Fontolan, L., Economo, M. N., Li, N., Romani, S., & Svoboda, K. (2021). Attractor dynamics gate cortical information flow during decision-making . Nature Neuroscience . 24 (6), 843-850. Franke, K., Willeke, K. F., Ponder, K., Galdamez, M., Muhammad, T., Patel, S., Froudarakis, E., Reimer, J., Sinz, F., & Tolias, A. (2021). Behavioral state tunes mouse vision to ethological features through pupil dilation . bioRxiv . Jacobsen, R. I., Nair, R. R., Obenhaus, H. A., Donato, F., Slettmoen, T., Moser, M.-B., & Moser, E. I. (2021). All-viral tracing of monosynaptic inputs to single birthdate-defined neurons in the intact brain . bioRxiv . Laboratory, T. I. B., Aguillon-Rodriguez, V., Angelaki, D., Bayer, H., Bonacchi, N., Carandini, M., Cazettes, F., Chapuis, G., Churchland, A. K., Dan, Y.others. (2021). Standardized and reproducible measurement of decision-making in mice . eLife , 10 . Strauss, S., Korympidou, M. M., Ran, Y., Franke, K., Schubert, T., Baden, T., Berens, P., Euler, T., & Vlasits, A. L. (2021). Center-surround interactions underlie bipolar cell motion sensing in the mouse retina . bioRxiv . Subramaniyan, M., Manivannan, S., Chelur, V., Tsetsenis, T., Jiang, E., & Dani, J. A. (2021). Fear conditioning potentiates the hippocampal CA1 commissural pathway in vivo and increases awake phase sleep . Hippocampus , 31 (10), 1154\u20131175. Urai, A. E., Aguillon-Rodriguez, V., Laranjeira, I. C., Cazettes, F., Laboratory, T. I. B., Mainen, Z. F., & Churchland, A. K. (2021). Citric acid water as an alternative to water restriction for high-yield mouse behavior . Eneuro , 8 (1). Wal, A., Klein, F. J., Born, G., Busse, L., & Katzner, S. (2021). Evaluating visual cues modulates their representation in mouse visual and cingulate cortex . Journal of Neuroscience , 41 (15), 3531\u20133544. Wang, Y., Chiola, S., Yang, G., Russell, C., Armstrong, C. J., Wu, Y., Spampanato, J., Tarboton, P., Chang, A. N., Harmin, D. A.others. (2021). Modeling autism-associated SHANK3 deficiency using human cortico-striatal organoids generated from single neural rosettes . bioRxiv . 2020 \u00b6 Aguillon-Rodriguez, V., Angelaki, D. E., Bayer, H. M., Bonacchi, N., Carandini, M., Cazettes, F., Chapuis, G. A., Churchland, A. K., Dan, Y., Dewitt, E. E.others. (2020). A standardized and reproducible method to measure decision-making in mice . BioRxiv . Angelaki, D. E., Ng, J., Abrego, A. M., Cham, H. X., Asprodini, E. K., Dickman, J. D., & Laurens, J. (2020). A gravity-based three-dimensional compass in the mouse brain . Nature Communications , 11 (1), 1\u201313. Cotton, R. J., Sinz, F. H., & Tolias, A. S. (2020). Factorized neural processes for neural processes: K -shot prediction of neural responses . arXiv Preprint arXiv:2010.11810 . Heath, S. L., Christenson, M. P., Oriol, E., Saavedra-Weisenhaus, M., Kohn, J. R., & Behnia, R. (2020). Circuit mechanisms underlying chromatic encoding in drosophila photoreceptors . Current Biology . Laturnus, S., Kobak, D., & Berens, P. (2020). A systematic evaluation of interneuron morphology representations for cell type discrimination . Neuroinformatics , 18 (4), 591\u2013609. Sinz, F. H., Sachgau, C., Henninger, J., Benda, J., & Grewe, J. (2020). Simultaneous spike-time locking to multiple frequencies . Journal of Neurophysiology , 123 (6), 2355\u20132372. Yatsenko, D., Moreaux, L. C., Choi, J., Tolias, A., Shepard, K. L., & Roukes, M. L. (2020). Signal separability in integrated neurophotonics . bioRxiv . Zhao, Z., Klindt, D. A., Chagas, A. M., Szatko, K. P., Rogerson, L., Protti, D. A., Behrens, C., Dalkara, D., Schubert, T., Bethge, M., others. (2020). The temporal structure of the inner retina at a single glance . Scientific Reports , 10 (1), 1\u201317. 2019 \u00b6 Bonacchi, N., Chapuis, G., Churchland, A., Harris, K. D., Rossant, C., Sasaki, M., Shen, S., Steinmetz, N. A., Walker, E. Y., Winter, O., others. (2019). Data architecture and visualization for a large-scale neuroscience collaboration . BioRxiv , 827873. Cadena, S. A., Denfield, G. H., Walker, E. Y., Gatys, L. A., Tolias, A. S., Bethge, M., & Ecker, A. S. (2019). Deep convolutional models improve predictions of macaque V1 responses to natural images . PLoS Computational Biology , 15 (4), e1006897. Chettih, S. N., & Harvey, C. D. (2019). Single-neuron perturbations reveal feature-specific competition in V1 . Nature , 567 (7748), 334\u2013340. Fahey, P. G., Muhammad, T., Smith, C., Froudarakis, E., Cobos, E., Fu, J., Walker, E. Y., Yatsenko, D., Sinz, F. H., Reimer, J.others. (2019). A global map of orientation tuning in mouse visual cortex . bioRxiv , 745323. Laurens, J., Abrego, A., Cham, H., Popeney, B., Yu, Y., Rotem, N., Aarse, J., Asprodini, E. K., Dickman, J. D., & Angelaki, D. E. (2019). Multiplexed code of navigation variables in anterior limbic areas . bioRxiv , 684464. Liu, G., Froudarakis, E., Patel, J. M., Kochukov, M. Y., Pekarek, B., Hunt, P. J., Patel, M., Ung, K., Fu, C.-H., Jo, J.others. (2019). Target specific functions of EPL interneurons in olfactory circuits . Nature Communications , 10 (1), 1\u201314. Ros\u00f3n, M. R., Bauer, Y., Kotkat, A. H., Berens, P., Euler, T., & Busse, L. (2019). Mouse dLGN receives functional input from a diverse population of retinal ganglion cells with limited convergence . Neuron , 102 (2), 462\u2013476. Walker, E. Y., Sinz, F. H., Cobos, E., Muhammad, T., Froudarakis, E., Fahey, P. G., Ecker, A. S., Reimer, J., Pitkow, X., & Tolias, A. S. (2019). Inception loops discover what excites neurons most using deep predictive models . Nature Neuroscience , 22 (12), 2060\u20132065. 2018 \u00b6 Denfield, G. H., Ecker, A. S., Shinn, T. J., Bethge, M., & Tolias, A. S. (2018). Attentional fluctuations induce shared variability in macaque primary visual cortex . Nature Communications , 9 (1), 2654. Ecker, A. S., Sinz, F. H., Froudarakis, E., Fahey, P. G., Cadena, S. A., Walker, E. Y., Cobos, E., Reimer, J., Tolias, A. S., & Bethge, M. (2018). A rotation-equivariant convolutional neural network model of primary visual cortex . arXiv Preprint arXiv:1809.10504 . Sinz, F., Ecker, A. S., Fahey, P., Walker, E., Cobos, E., Froudarakis, E., Yatsenko, D., Pitkow, Z., Reimer, J., & Tolias, A. (2018). Stimulus domain transfer in recurrent models for large scale cortical population prediction on video . Advances in Neural Information Processing Systems , 7199\u20137210. Walker, E. Y., Sinz, F. H., Froudarakis, E., Fahey, P. G., Muhammad, T., Ecker, A. S., Cobos, E., Reimer, J., Pitkow, X., & Tolias, A. S. (2018). Inception in visual cortex: In vivo-silico loops reveal most exciting images . bioRxiv , 506956. 2017 \u00b6 Franke, K., Berens, P., Schubert, T., Bethge, M., Euler, T., & Baden, T. (2017). Inhibition decorrelates visual feature representations in the inner retina . Nature , 542 (7642), 439. Jurjut, O., Georgieva, P., Busse, L., & Katzner, S. (2017). Learning enhances sensory processing in mouse V1 before improving behavior . Journal of Neuroscience , 37 (27), 6460\u20136474. Shan, K. Q., Lubenov, E. V., & Siapas, A. G. (2017). Model-based spike sorting with a mixture of drifting t-distributions . Journal of Neuroscience Methods , 288 , 82\u201398. 2016 \u00b6 Baden, T., Berens, P., Franke, K., Ros\u00f3n, M. R., Bethge, M., & Euler, T. (2016). The functional diversity of retinal ganglion cells in the mouse . Nature , 529 (7586), 345\u2013350. Cadwell, C. R., Palasantza, A., Jiang, X., Berens, P., Deng, Q., Yilmaz, M., Reimer, J., Shen, S., Bethge, M., Tolias, K. F., others. (2016). Electrophysiological, transcriptomic and morphologic profiling of single neurons using patch-seq . Nature Biotechnology , 34 (2), 199\u2013203. Hartmann, L., Drewe-Bo\u00df, P., Wie\u00dfner, T., Wagner, G., Geue, S., Lee, H.-C., Oberm\u00fcller, D. M., Kahles, A., Behr, J., Sinz, F. H.others. (2016). Alternative splicing substantially diversifies the transcriptome during early photomorphogenesis and correlates with the energy availability in arabidopsis . The Plant Cell , 28 (11), 2715\u20132734. Khastkhodaei, Z., Jurjut, O., Katzner, S., & Busse, L. (2016). Mice can use second-order, contrast-modulated stimuli to guide visual perception . Journal of Neuroscience , 36 (16), 4457\u20134469. Reimer, J., McGinley, M. J., Liu, Y., Rodenkirch, C., Wang, Q., McCormick, D. A., & Tolias, A. S. (2016). Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex . Nature Communications , 7 , 13289. Shan, K. Q., Lubenov, E. V., Papadopoulou, M., & Siapas, A. G. (2016). Spatial tuning and brain state account for dorsal hippocampal CA1 activity in a non-spatial learning task . eLife , 5 , e14321. 2015 \u00b6 Jiang, X., Shen, S., Cadwell, C. R., Berens, P., Sinz, F., Ecker, A. S., Patel, S., & Tolias, A. S. (2015). Principles of connectivity among morphologically defined cell types in adult neocortex . Science , 350 (6264), aac9462. Yatsenko, D., Josi\u0107, K., Ecker, A. S., Froudarakis, E., Cotton, R. J., & Tolias, A. S. (2015). Improved estimation and interpretation of correlations in neural circuits . PLoS Comput Biol , 11 (3), e1004083. 2014 \u00b6 Ecker, A. S., Berens, P., Cotton, R. J., Subramaniyan, M., Denfield, G. H., Cadwell, C. R., Smirnakis, S. M., Bethge, M., & Tolias, A. S. (2014). State dependence of noise correlations in macaque primary visual cortex . Neuron , 82 (1), 235\u2013248. Erisken, S., Vaiceliunaite, A., Jurjut, O., Fiorini, M., Katzner, S., & Busse, L. (2014). Effects of locomotion extend throughout the mouse early visual system . Current Biology , 24 (24), 2899\u20132907. Froudarakis, E., Berens, P., Ecker, A. S., Cotton, R. J., Sinz, F. H., Yatsenko, D., Saggau, P., Bethge, M., & Tolias, A. S. (2014). Population code in mouse V1 facilitates readout of natural scenes through increased sparseness . Nat Neurosci , 17 (6), 851\u2013857. Reimer, J., Froudarakis, E., Cadwell, C. R., Yatsenko, D., Denfield, G. H., & Tolias, A. S. (2014). Pupil fluctuations track fast switching of cortical states during quiet wakefulness . Neuron , 84 (2), 355\u2013362. 2013 \u00b6 Cotton, R. J., Froudarakis, E., Storer, P., Saggau, P., & Tolias, A. S. (2013). Three-dimensional mapping of microcircuit correlation structure . Frontiers in Neural Circuits , 7 , 151. Vaiceliunaite, A., Erisken, S., Franzen, F., Katzner, S., & Busse, L. (2013). Spatial integration in mouse primary visual cortex . Journal of Neurophysiology , 110 (4), 964\u2013972.","title":"Publications"},{"location":"publications/#publications","text":"The following publications relied on DataJoint open-source software for data analysis. If you would like make additions or corrections, please send an email to support@datajoint.com. If your work uses DataJoint or DataJoint Elements, please cite the following: DataJoint Yatsenko D, Reimer J, Ecker AS, Walker EY, Sinz F, Berens P, Hoenselaar A, Cotton RJ, Siapas AS, Tolias AS. DataJoint: managing big scientific data using MATLAB or Python . bioRxiv. 2015 Jan 1:031658. Yatsenko D, Walker EY, Tolias AS. DataJoint: a simpler relational data model . arXiv:1807.11104. 2018 Jul 29. DataJoint Elements Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D, Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for Neurophysiology . bioRxiv. 2021 Jan 1.","title":"Publications"},{"location":"publications/#2022","text":"Wang, Y., Chiola, S., Yang, G., Russell, C., Armstrong, C. J., Wu, Y., ... & Shcheglovitov, A. (2022). Modeling human telencephalic development and autism-associated SHANK3 deficiency using organoids generated from single neural rosettes . Nature Communications , 13(1), 1-25. Franke, K., Willeke, K. F., Ponder, K., Galdamez, M., Zhou, N., Muhammad, T., ... & Tolias, A. S. (2022). State-dependent pupil dilation rapidly shifts visual feature selectivity . Nature , 1-7. Pettit, N. H., Yap, E., Greenberg, M. E., Harvey, C. D. (2022). Fos ensembles encode and shape stable spatial maps in the hippocampus . Nature . Saunders, J. L., Ott, L. A., Wehr, M. (2022). AUTOPILOT: Automating experiments with lots of Raspberry Pis . bioRxiv . Born, G. (2022). The effect of feedback on sensory processing in the mouse early visual system . Doctoral dissertation . Cadena, S. A., Willeke, K. F., Restivo, K., Denfield, G., Sinz, F. H., Bethge, M., ... & Ecker, A. S. (2022). Diverse task-driven modeling of macaque V4 reveals functional specialization towards semantic tasks. . bioRxiv . Cotton, R. J. (2022). PosePipe: Open-Source Human Pose Estimation Pipeline for Clinical Research . arXiv . 2203.08792. Cotton, R. J., McClerklin, E., Cimorelli, A., & Patel, A. (2022). Spatiotemporal characterization of gait from monocular videos with transformers . Cotton, R. J., McClerklin, E., Cimorelli, A., Patel, A., & Karakostas, T. (2022). Transforming Gait: Video-Based Spatiotemporal Gait Analysis . arXiv . 2203.09371. Fu, J., Willeke, K. F., Pierzchlewicz, P. A., Muhammad, T., Denfield, G. H., Sinz, F. H., & Tolias, A. S. (2022). Heterogeneous Orientation Tuning Across Sub-Regions of Receptive Fields of V1 Neurons in Mice . Available at SSRN 4029075 . Goetz, J., Jessen, Z. F., Jacobi, A., Mani, A., Cooler, S., Greer, D., ... & Schwartz, G. W. (2022). Unified classification of mouse retinal ganglion cells using function, morphology, and gene expression . Cell reports , 40(2), 111040. Jaffe, A. (2022). Optical investigation of microcircuit computations in mouse primary visual cortex . Doctoral dissertation . Obenhaus, H.A., Zong, W., Jacobsen, R.I., Rose, T., Donato, F., Chen, L., Cheng, H., Bonhoeffer, T., Moser, M.B. & Moser, E.I. (2022). Functional network topography of the medial entorhinal cortex . Proceedings of the National Academy of Sciences , 119 (7). Roukes, M. L. (2022, May). The Integrated Neurophotonics Paradigm . In CLEO: Applications and Technology (pp. ATh4I-6). Optica Publishing Group. Sanchez, M., Moore, D., Johnson, E. C., Wester, B., Lichtman, J. W., & Gray-Roncal, W. (2022). Connectomics Annotation Metadata Standardization for Increased Accessibility and Queryability . Frontiers in Neuroinformatics . Spacek, M. A., Crombie, D., Bauer, Y., Born, G., Liu, X., Katzner, S., & Busse, L. (2022). Robust effects of corticothalamic feedback and behavioral state on movie responses in mouse dLGN . Elife , 11, e70469. Tseng, S. Y., Chettih, S. N., Arlt, C., Barroso-Luque, R., & Harvey, C. D. (2022). Shared and specialized coding across posterior cortical areas for dynamic navigation decisions. . Neuron . Turner, N. L., Macrina, T., Bae, J. A., Yang, R., Wilson, A. M., Schneider-Mizell, C., ... & Seung, H. S. (2022). Reconstruction of neocortex: Organelles, compartments, cells, circuits, and activity. . Cell, 185 (6), 1082-1100. Ustyuzhaninov, I., Burg, M.F., Cadena, S.A., Fu, J., Muhammad, T., Ponder, K., Froudarakis, E., Ding, Z., Bethge, M., Tolias, A. & Ecker, A.S. (2022). Digital twin reveals combinatorial code of non-linear computations in the mouse primary visual cortex . bioRxiv . Willeke, K. F., Fahey, P. G., Bashiri, M., Pede, L., Burg, M. F., Blessing, C., ... & Sinz, F. H. (2022). The Sensorium competition on predicting large-scale mouse primary visual cortex activity . arXiv preprint arXiv:2206.08666 .","title":"2022 "},{"location":"publications/#2021","text":"Bae, J. A., Baptiste, M., Bodor, A. L., Brittain, D., Buchanan, J., Bumbarger, D. J., Castro, M. A., Celii, B., Cobos, E., Collman, F.others. (2021). Functional connectomics spanning multiple areas of mouse visual cortex . bioRxiv . Born, G., Schneider-Soupiadis, F. A., Erisken, S., Vaiceliunaite, A., Lao, C. L., Mobarhan, M. H., Spacek, M. A., Einevoll, G. T., & Busse, L. (2021). Corticothalamic feedback sculpts visual spatial integration in mouse thalamus . Nature Neuroscience , 24 (12), 1711\u20131720. Burg, M. F., Cadena, S. A., Denfield, G. H., Walker, E. Y., Tolias, A. S., Bethge, M., & Ecker, A. S. (2021). Learning divisive normalization in primary visual cortex . PLOS Computational Biology , 17 (6), e1009028. Claudi, F., Campagner, D., & Branco, T. (2021). Innate heuristics and fast learning support escape route selection in mice . bioRxiv . Cohrs, K.H. (2021). Investigation of feedback mechanisms in visual cortex using deep learning models [Master\u2019s thesis]. University of G\u00f6ttingen. Finkelstein, A., Fontolan, L., Economo, M. N., Li, N., Romani, S., & Svoboda, K. (2021). Attractor dynamics gate cortical information flow during decision-making . Nature Neuroscience . 24 (6), 843-850. Franke, K., Willeke, K. F., Ponder, K., Galdamez, M., Muhammad, T., Patel, S., Froudarakis, E., Reimer, J., Sinz, F., & Tolias, A. (2021). Behavioral state tunes mouse vision to ethological features through pupil dilation . bioRxiv . Jacobsen, R. I., Nair, R. R., Obenhaus, H. A., Donato, F., Slettmoen, T., Moser, M.-B., & Moser, E. I. (2021). All-viral tracing of monosynaptic inputs to single birthdate-defined neurons in the intact brain . bioRxiv . Laboratory, T. I. B., Aguillon-Rodriguez, V., Angelaki, D., Bayer, H., Bonacchi, N., Carandini, M., Cazettes, F., Chapuis, G., Churchland, A. K., Dan, Y.others. (2021). Standardized and reproducible measurement of decision-making in mice . eLife , 10 . Strauss, S., Korympidou, M. M., Ran, Y., Franke, K., Schubert, T., Baden, T., Berens, P., Euler, T., & Vlasits, A. L. (2021). Center-surround interactions underlie bipolar cell motion sensing in the mouse retina . bioRxiv . Subramaniyan, M., Manivannan, S., Chelur, V., Tsetsenis, T., Jiang, E., & Dani, J. A. (2021). Fear conditioning potentiates the hippocampal CA1 commissural pathway in vivo and increases awake phase sleep . Hippocampus , 31 (10), 1154\u20131175. Urai, A. E., Aguillon-Rodriguez, V., Laranjeira, I. C., Cazettes, F., Laboratory, T. I. B., Mainen, Z. F., & Churchland, A. K. (2021). Citric acid water as an alternative to water restriction for high-yield mouse behavior . Eneuro , 8 (1). Wal, A., Klein, F. J., Born, G., Busse, L., & Katzner, S. (2021). Evaluating visual cues modulates their representation in mouse visual and cingulate cortex . Journal of Neuroscience , 41 (15), 3531\u20133544. Wang, Y., Chiola, S., Yang, G., Russell, C., Armstrong, C. J., Wu, Y., Spampanato, J., Tarboton, P., Chang, A. N., Harmin, D. A.others. (2021). Modeling autism-associated SHANK3 deficiency using human cortico-striatal organoids generated from single neural rosettes . bioRxiv .","title":"2021 "},{"location":"publications/#2020","text":"Aguillon-Rodriguez, V., Angelaki, D. E., Bayer, H. M., Bonacchi, N., Carandini, M., Cazettes, F., Chapuis, G. A., Churchland, A. K., Dan, Y., Dewitt, E. E.others. (2020). A standardized and reproducible method to measure decision-making in mice . BioRxiv . Angelaki, D. E., Ng, J., Abrego, A. M., Cham, H. X., Asprodini, E. K., Dickman, J. D., & Laurens, J. (2020). A gravity-based three-dimensional compass in the mouse brain . Nature Communications , 11 (1), 1\u201313. Cotton, R. J., Sinz, F. H., & Tolias, A. S. (2020). Factorized neural processes for neural processes: K -shot prediction of neural responses . arXiv Preprint arXiv:2010.11810 . Heath, S. L., Christenson, M. P., Oriol, E., Saavedra-Weisenhaus, M., Kohn, J. R., & Behnia, R. (2020). Circuit mechanisms underlying chromatic encoding in drosophila photoreceptors . Current Biology . Laturnus, S., Kobak, D., & Berens, P. (2020). A systematic evaluation of interneuron morphology representations for cell type discrimination . Neuroinformatics , 18 (4), 591\u2013609. Sinz, F. H., Sachgau, C., Henninger, J., Benda, J., & Grewe, J. (2020). Simultaneous spike-time locking to multiple frequencies . Journal of Neurophysiology , 123 (6), 2355\u20132372. Yatsenko, D., Moreaux, L. C., Choi, J., Tolias, A., Shepard, K. L., & Roukes, M. L. (2020). Signal separability in integrated neurophotonics . bioRxiv . Zhao, Z., Klindt, D. A., Chagas, A. M., Szatko, K. P., Rogerson, L., Protti, D. A., Behrens, C., Dalkara, D., Schubert, T., Bethge, M., others. (2020). The temporal structure of the inner retina at a single glance . Scientific Reports , 10 (1), 1\u201317.","title":"2020 "},{"location":"publications/#2019","text":"Bonacchi, N., Chapuis, G., Churchland, A., Harris, K. D., Rossant, C., Sasaki, M., Shen, S., Steinmetz, N. A., Walker, E. Y., Winter, O., others. (2019). Data architecture and visualization for a large-scale neuroscience collaboration . BioRxiv , 827873. Cadena, S. A., Denfield, G. H., Walker, E. Y., Gatys, L. A., Tolias, A. S., Bethge, M., & Ecker, A. S. (2019). Deep convolutional models improve predictions of macaque V1 responses to natural images . PLoS Computational Biology , 15 (4), e1006897. Chettih, S. N., & Harvey, C. D. (2019). Single-neuron perturbations reveal feature-specific competition in V1 . Nature , 567 (7748), 334\u2013340. Fahey, P. G., Muhammad, T., Smith, C., Froudarakis, E., Cobos, E., Fu, J., Walker, E. Y., Yatsenko, D., Sinz, F. H., Reimer, J.others. (2019). A global map of orientation tuning in mouse visual cortex . bioRxiv , 745323. Laurens, J., Abrego, A., Cham, H., Popeney, B., Yu, Y., Rotem, N., Aarse, J., Asprodini, E. K., Dickman, J. D., & Angelaki, D. E. (2019). Multiplexed code of navigation variables in anterior limbic areas . bioRxiv , 684464. Liu, G., Froudarakis, E., Patel, J. M., Kochukov, M. Y., Pekarek, B., Hunt, P. J., Patel, M., Ung, K., Fu, C.-H., Jo, J.others. (2019). Target specific functions of EPL interneurons in olfactory circuits . Nature Communications , 10 (1), 1\u201314. Ros\u00f3n, M. R., Bauer, Y., Kotkat, A. H., Berens, P., Euler, T., & Busse, L. (2019). Mouse dLGN receives functional input from a diverse population of retinal ganglion cells with limited convergence . Neuron , 102 (2), 462\u2013476. Walker, E. Y., Sinz, F. H., Cobos, E., Muhammad, T., Froudarakis, E., Fahey, P. G., Ecker, A. S., Reimer, J., Pitkow, X., & Tolias, A. S. (2019). Inception loops discover what excites neurons most using deep predictive models . Nature Neuroscience , 22 (12), 2060\u20132065.","title":"2019 "},{"location":"publications/#2018","text":"Denfield, G. H., Ecker, A. S., Shinn, T. J., Bethge, M., & Tolias, A. S. (2018). Attentional fluctuations induce shared variability in macaque primary visual cortex . Nature Communications , 9 (1), 2654. Ecker, A. S., Sinz, F. H., Froudarakis, E., Fahey, P. G., Cadena, S. A., Walker, E. Y., Cobos, E., Reimer, J., Tolias, A. S., & Bethge, M. (2018). A rotation-equivariant convolutional neural network model of primary visual cortex . arXiv Preprint arXiv:1809.10504 . Sinz, F., Ecker, A. S., Fahey, P., Walker, E., Cobos, E., Froudarakis, E., Yatsenko, D., Pitkow, Z., Reimer, J., & Tolias, A. (2018). Stimulus domain transfer in recurrent models for large scale cortical population prediction on video . Advances in Neural Information Processing Systems , 7199\u20137210. Walker, E. Y., Sinz, F. H., Froudarakis, E., Fahey, P. G., Muhammad, T., Ecker, A. S., Cobos, E., Reimer, J., Pitkow, X., & Tolias, A. S. (2018). Inception in visual cortex: In vivo-silico loops reveal most exciting images . bioRxiv , 506956.","title":"2018 "},{"location":"publications/#2017","text":"Franke, K., Berens, P., Schubert, T., Bethge, M., Euler, T., & Baden, T. (2017). Inhibition decorrelates visual feature representations in the inner retina . Nature , 542 (7642), 439. Jurjut, O., Georgieva, P., Busse, L., & Katzner, S. (2017). Learning enhances sensory processing in mouse V1 before improving behavior . Journal of Neuroscience , 37 (27), 6460\u20136474. Shan, K. Q., Lubenov, E. V., & Siapas, A. G. (2017). Model-based spike sorting with a mixture of drifting t-distributions . Journal of Neuroscience Methods , 288 , 82\u201398.","title":"2017 "},{"location":"publications/#2016","text":"Baden, T., Berens, P., Franke, K., Ros\u00f3n, M. R., Bethge, M., & Euler, T. (2016). The functional diversity of retinal ganglion cells in the mouse . Nature , 529 (7586), 345\u2013350. Cadwell, C. R., Palasantza, A., Jiang, X., Berens, P., Deng, Q., Yilmaz, M., Reimer, J., Shen, S., Bethge, M., Tolias, K. F., others. (2016). Electrophysiological, transcriptomic and morphologic profiling of single neurons using patch-seq . Nature Biotechnology , 34 (2), 199\u2013203. Hartmann, L., Drewe-Bo\u00df, P., Wie\u00dfner, T., Wagner, G., Geue, S., Lee, H.-C., Oberm\u00fcller, D. M., Kahles, A., Behr, J., Sinz, F. H.others. (2016). Alternative splicing substantially diversifies the transcriptome during early photomorphogenesis and correlates with the energy availability in arabidopsis . The Plant Cell , 28 (11), 2715\u20132734. Khastkhodaei, Z., Jurjut, O., Katzner, S., & Busse, L. (2016). Mice can use second-order, contrast-modulated stimuli to guide visual perception . Journal of Neuroscience , 36 (16), 4457\u20134469. Reimer, J., McGinley, M. J., Liu, Y., Rodenkirch, C., Wang, Q., McCormick, D. A., & Tolias, A. S. (2016). Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex . Nature Communications , 7 , 13289. Shan, K. Q., Lubenov, E. V., Papadopoulou, M., & Siapas, A. G. (2016). Spatial tuning and brain state account for dorsal hippocampal CA1 activity in a non-spatial learning task . eLife , 5 , e14321.","title":"2016 "},{"location":"publications/#2015","text":"Jiang, X., Shen, S., Cadwell, C. R., Berens, P., Sinz, F., Ecker, A. S., Patel, S., & Tolias, A. S. (2015). Principles of connectivity among morphologically defined cell types in adult neocortex . Science , 350 (6264), aac9462. Yatsenko, D., Josi\u0107, K., Ecker, A. S., Froudarakis, E., Cotton, R. J., & Tolias, A. S. (2015). Improved estimation and interpretation of correlations in neural circuits . PLoS Comput Biol , 11 (3), e1004083.","title":"2015 "},{"location":"publications/#2014","text":"Ecker, A. S., Berens, P., Cotton, R. J., Subramaniyan, M., Denfield, G. H., Cadwell, C. R., Smirnakis, S. M., Bethge, M., & Tolias, A. S. (2014). State dependence of noise correlations in macaque primary visual cortex . Neuron , 82 (1), 235\u2013248. Erisken, S., Vaiceliunaite, A., Jurjut, O., Fiorini, M., Katzner, S., & Busse, L. (2014). Effects of locomotion extend throughout the mouse early visual system . Current Biology , 24 (24), 2899\u20132907. Froudarakis, E., Berens, P., Ecker, A. S., Cotton, R. J., Sinz, F. H., Yatsenko, D., Saggau, P., Bethge, M., & Tolias, A. S. (2014). Population code in mouse V1 facilitates readout of natural scenes through increased sparseness . Nat Neurosci , 17 (6), 851\u2013857. Reimer, J., Froudarakis, E., Cadwell, C. R., Yatsenko, D., Denfield, G. H., & Tolias, A. S. (2014). Pupil fluctuations track fast switching of cortical states during quiet wakefulness . Neuron , 84 (2), 355\u2013362.","title":"2014 "},{"location":"publications/#2013","text":"Cotton, R. J., Froudarakis, E., Storer, P., Saggau, P., & Tolias, A. S. (2013). Three-dimensional mapping of microcircuit correlation structure . Frontiers in Neural Circuits , 7 , 151. Vaiceliunaite, A., Erisken, S., Franzen, F., Katzner, S., & Busse, L. (2013). Spatial integration in mouse primary visual cortex . Journal of Neurophysiology , 110 (4), 964\u2013972.","title":"2013 "},{"location":"welcome/","text":"Howdy \u00b6 Welcome to the home for DataJoint documentation. Here we'll help get you to the right place quickly. The DataJoint ecosystem is divided into 2 distinct areas: Core : Fully open-source projects built and designed specifically to support the DataJoint Mantra . Elements : Fully open-source, data pipelines for neuroscience built with DataJoint Core . Citation \u00b6 If your work uses the DataJoint API's and DataJoint Elements, please cite the respective Research Resource Identifiers (RRIDs) and manuscripts. DataJoint API for Python or MATLAB Yatsenko D, Reimer J, Ecker AS, Walker EY, Sinz F, Berens P, Hoenselaar A, Cotton RJ, Siapas AS, Tolias AS. DataJoint: managing big scientific data using MATLAB or Python. bioRxiv. 2015 Jan 1:031658. doi: https://doi.org/10.1101/031658 DataJoint ( RRID:SCR_014543 ) - DataJoint <Select Python or MATLAB> (version <Enter version number> ) DataJoint Elements Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D, Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358 DataJoint Elements ( RRID:SCR_021894 ) - Element Enter Element name (version <Enter version number> ) Feedback \u00b6 DataJoint API's, DataJoint Web GUI's, and DataJoint Elements are supported by NIH grant U24 NS116470 for disseminating open-source software for neuroscience research. Your feedback is essential for continued funding. Your feedback also helps shape the technology development roadmap for the DataJoint ecosystem. Please tell us about your projects by filling out the DataJoint Census .","title":"Welcome"},{"location":"welcome/#howdy","text":"Welcome to the home for DataJoint documentation. Here we'll help get you to the right place quickly. The DataJoint ecosystem is divided into 2 distinct areas: Core : Fully open-source projects built and designed specifically to support the DataJoint Mantra . Elements : Fully open-source, data pipelines for neuroscience built with DataJoint Core .","title":"Howdy"},{"location":"welcome/#citation","text":"If your work uses the DataJoint API's and DataJoint Elements, please cite the respective Research Resource Identifiers (RRIDs) and manuscripts. DataJoint API for Python or MATLAB Yatsenko D, Reimer J, Ecker AS, Walker EY, Sinz F, Berens P, Hoenselaar A, Cotton RJ, Siapas AS, Tolias AS. DataJoint: managing big scientific data using MATLAB or Python. bioRxiv. 2015 Jan 1:031658. doi: https://doi.org/10.1101/031658 DataJoint ( RRID:SCR_014543 ) - DataJoint <Select Python or MATLAB> (version <Enter version number> ) DataJoint Elements Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D, Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358 DataJoint Elements ( RRID:SCR_021894 ) - Element Enter Element name (version <Enter version number> )","title":"Citation"},{"location":"welcome/#feedback","text":"DataJoint API's, DataJoint Web GUI's, and DataJoint Elements are supported by NIH grant U24 NS116470 for disseminating open-source software for neuroscience research. Your feedback is essential for continued funding. Your feedback also helps shape the technology development roadmap for the DataJoint ecosystem. Please tell us about your projects by filling out the DataJoint Census .","title":"Feedback"},{"location":"community/contribution/","text":"Contribution Guidelines \u00b6 Thank you for your interest in contributing! \ud83e\udd1d To help keep everyone in alignment and coordinated in the community effort, we\u2019ve created this document. It serves as the contribution guideline that outlines how open-source software development is to be conducted. Any software development that makes reference to this document can be assumed to adopt the policies outlined below. We\u2019ve structured the guideline in a FAQ (frequently asked questions) format to make it easier to digest. Feel free to review the questions below to determine any specific policy. The principal maintainer of DataJoint and associated tools is the DataJoint company. The pronouns \u201cwe\u201d and \u201cus\u201d in this guideline refer to the principal maintainers. We invite reviews and contributions of the open-source software. We compiled these guidelines to make this work clear and efficient. 1) Which issue should I contribute towards? \u00b6 There are three primary things to consider when looking to contribute. Availability: An indication of whether anyone is currently working on a fix for the given issue. Availability is indicated by who is assigned . Issues that are unassigned mean that there is no one yet working on resolving the issue and the issue is available for someone to work on. If an issue has been assigned, then any additional work on that issue should be coordinated with the assignee. Specification: In order for issues to be properly addressed, the requirements of satisfying and closing the issue should be clear. If it is not, a label will be added as unspecified . This could be due to more debug info being necessary, more details on intended behavior, or perhaps that further discussion is required to determine a good solution. Feel free to help us arrive at a proper specification. Priority: As a community, we work on a concerted effort to bring about the realization of the milestones. We utilize milestones as a planning tool to help focus a group of changes around a release. To determine the priority of issues, simply have a look at the next milestone that is expected to arrive. Therefore, each milestone following this can be understood as lower in priority respectively. Bear in mind that much like a hurricane forecast, the execution plan is much more likely to be accurate the closer to today\u2019s date as opposed to milestones further out. Extremely low priority issues are assigned to the Backburner milestone. Since Backburner does not have a target date, this indicates that its issues may be deferred indefinitely. Occasionally the maintainers will move issues from Backburner as it makes sense to address them within a release. Also, issues unassigned to a milestone can be understood as new issues which have not been triaged. After considering the above, you may comment on the issue you\u2019d like to help fix and a maintainer will assign it to you. 2) What is the proper etiquette for proposing changes as contribution? \u00b6 What is generally expected from new contributions are the following: Any proposed contributor changes should be introduced in the form of a pull request (PR) from their fork. Proper branch target specified. The following are the generally the available branches that can be targeted: main or master : Represents the single source of truth and the latest in completed development. pre : Represents the source at the point of the last stable release. For larger more involved changes, a maintainer may determine it best to create a feature-specific branch and adjust the PR accordingly. A summary description that describes the overall intent behind the PR. Proper links to the issue(s) that the PR serves to resolve. Newly introduced changes must pass any required checks. Typically as it relates to tests, this means: No syntax errors No integration errors No style errors e.g. PEP8, etc. Similar or better code coverage Additional documentation to reflect new feature or behavior introduced. Necessary updates to the changelog following Keep a Changelog convention. A contributor should not approve or merge their own PR. Reviewer suggestions or feedback should not be directly committed to a branch on a contributor\u2019s fork. A less intrusive way to collaborate would be for the reviewer to PR to the contributor\u2019s fork/branch that is associated with the main PR currently in review. Maintainers will also ensure that PR\u2019s have the appropriate assignment for reviewer, milestone, and project. 3) How can I track the progress of an issue that has been assigned? \u00b6 Since milestones represent the development plan, projects represent the actual execution. Projects are typically fixed-time sprints (1-2 weeks). A \u2018workable\u2019 number of issues that have been assigned to developers and assigned to the next milestone are selected and tracked in each project to provide greater granularity in the week-to-week progress. Automation is included observing the Automated kanban with reviews template. Maintainers will adjust the project assignment to reflect the order in which to resolve the milestone issues. 4) What is the release process? How do I know when my merged contribution will officially make it into a release? \u00b6 Releases follow the standard definition of semantic versioning . Meaning: MAJOR . MINOR . PATCH MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards compatible manner, and PATCH version when you make backwards compatible bug fixes. Each release requires tagging the commit appropriately and is then issued in the normal medium for release e.g. PyPi, NPM, YARN, GitHub Release, etc. Minor releases are triggered when all the issues assigned to a milestone are resolved and closed. Patch releases are triggered periodically from main or master after a reasonable number of PR merges have come in. 5) I am not yet too comfortable contributing but would like to engage the community. What is the policy on community engagement? \u00b6 In order to follow the appropriate process and setting, please reference the following flow for your desired mode of engagement: 5a) Generally, how do I perform _ ___? \u00b6 If the documentation does not provide clear enough instruction, please see StackOverflow posts related to the datajoint tag or ask a new question tagging it appropriately. You may refer to our datajoint tag wiki for more details on its proper use. 5b) I just encountered this error, how can I resolve it? \u00b6 Please see StackOverflow posts related to the datajoint tag or ask a new question tagging it appropriately. You may refer to our datajoint tag wiki for more details on its proper use. 5c) I just encountered this error and I am sure it is a bug, how do I report it? \u00b6 Please file it under the issue tracker associated with the open-source software. 5d) I have an idea or new feature request, how do I submit it? \u00b6 Please file it under the issue tracker associated with the open-source software. 5e) I am curious why the maintainers choose to _ ___? i.e. questions that are \u2018opinionated\u2019 in nature with answers that some might disagree. \u00b6 Please join the community on the DataJoint Slack and ask on the most relevant channel. There, you may engage directly with the maintainers for proper discourse. 5f) What is the timeline or roadmap for the release of certain supported features? \u00b6 Please refer to milestones and projects associated with the open-source software. 5g) I need urgent help best suited for live debugging, how can I reach out directly? \u00b6 Please join the community on the DataJoint Slack and ask on the most relevant channel. Please bear in mind that as open-source community software, availability of the maintainers might be limited.","title":"Contribution"},{"location":"community/contribution/#contribution-guidelines","text":"Thank you for your interest in contributing! \ud83e\udd1d To help keep everyone in alignment and coordinated in the community effort, we\u2019ve created this document. It serves as the contribution guideline that outlines how open-source software development is to be conducted. Any software development that makes reference to this document can be assumed to adopt the policies outlined below. We\u2019ve structured the guideline in a FAQ (frequently asked questions) format to make it easier to digest. Feel free to review the questions below to determine any specific policy. The principal maintainer of DataJoint and associated tools is the DataJoint company. The pronouns \u201cwe\u201d and \u201cus\u201d in this guideline refer to the principal maintainers. We invite reviews and contributions of the open-source software. We compiled these guidelines to make this work clear and efficient.","title":"Contribution Guidelines"},{"location":"community/contribution/#1-which-issue-should-i-contribute-towards","text":"There are three primary things to consider when looking to contribute. Availability: An indication of whether anyone is currently working on a fix for the given issue. Availability is indicated by who is assigned . Issues that are unassigned mean that there is no one yet working on resolving the issue and the issue is available for someone to work on. If an issue has been assigned, then any additional work on that issue should be coordinated with the assignee. Specification: In order for issues to be properly addressed, the requirements of satisfying and closing the issue should be clear. If it is not, a label will be added as unspecified . This could be due to more debug info being necessary, more details on intended behavior, or perhaps that further discussion is required to determine a good solution. Feel free to help us arrive at a proper specification. Priority: As a community, we work on a concerted effort to bring about the realization of the milestones. We utilize milestones as a planning tool to help focus a group of changes around a release. To determine the priority of issues, simply have a look at the next milestone that is expected to arrive. Therefore, each milestone following this can be understood as lower in priority respectively. Bear in mind that much like a hurricane forecast, the execution plan is much more likely to be accurate the closer to today\u2019s date as opposed to milestones further out. Extremely low priority issues are assigned to the Backburner milestone. Since Backburner does not have a target date, this indicates that its issues may be deferred indefinitely. Occasionally the maintainers will move issues from Backburner as it makes sense to address them within a release. Also, issues unassigned to a milestone can be understood as new issues which have not been triaged. After considering the above, you may comment on the issue you\u2019d like to help fix and a maintainer will assign it to you.","title":"1) Which issue should I contribute towards?"},{"location":"community/contribution/#2-what-is-the-proper-etiquette-for-proposing-changes-as-contribution","text":"What is generally expected from new contributions are the following: Any proposed contributor changes should be introduced in the form of a pull request (PR) from their fork. Proper branch target specified. The following are the generally the available branches that can be targeted: main or master : Represents the single source of truth and the latest in completed development. pre : Represents the source at the point of the last stable release. For larger more involved changes, a maintainer may determine it best to create a feature-specific branch and adjust the PR accordingly. A summary description that describes the overall intent behind the PR. Proper links to the issue(s) that the PR serves to resolve. Newly introduced changes must pass any required checks. Typically as it relates to tests, this means: No syntax errors No integration errors No style errors e.g. PEP8, etc. Similar or better code coverage Additional documentation to reflect new feature or behavior introduced. Necessary updates to the changelog following Keep a Changelog convention. A contributor should not approve or merge their own PR. Reviewer suggestions or feedback should not be directly committed to a branch on a contributor\u2019s fork. A less intrusive way to collaborate would be for the reviewer to PR to the contributor\u2019s fork/branch that is associated with the main PR currently in review. Maintainers will also ensure that PR\u2019s have the appropriate assignment for reviewer, milestone, and project.","title":"2) What is the proper etiquette for proposing changes as contribution?"},{"location":"community/contribution/#3-how-can-i-track-the-progress-of-an-issue-that-has-been-assigned","text":"Since milestones represent the development plan, projects represent the actual execution. Projects are typically fixed-time sprints (1-2 weeks). A \u2018workable\u2019 number of issues that have been assigned to developers and assigned to the next milestone are selected and tracked in each project to provide greater granularity in the week-to-week progress. Automation is included observing the Automated kanban with reviews template. Maintainers will adjust the project assignment to reflect the order in which to resolve the milestone issues.","title":"3) How can I track the progress of an issue that has been assigned?"},{"location":"community/contribution/#4-what-is-the-release-process-how-do-i-know-when-my-merged-contribution-will-officially-make-it-into-a-release","text":"Releases follow the standard definition of semantic versioning . Meaning: MAJOR . MINOR . PATCH MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards compatible manner, and PATCH version when you make backwards compatible bug fixes. Each release requires tagging the commit appropriately and is then issued in the normal medium for release e.g. PyPi, NPM, YARN, GitHub Release, etc. Minor releases are triggered when all the issues assigned to a milestone are resolved and closed. Patch releases are triggered periodically from main or master after a reasonable number of PR merges have come in.","title":"4) What is the release process? How do I know when my merged contribution will officially make it into a release?"},{"location":"community/contribution/#5-i-am-not-yet-too-comfortable-contributing-but-would-like-to-engage-the-community-what-is-the-policy-on-community-engagement","text":"In order to follow the appropriate process and setting, please reference the following flow for your desired mode of engagement:","title":"5) I am not yet too comfortable contributing but would like to engage the community. What is the policy on community engagement?"},{"location":"community/contribution/#5a-generally-how-do-i-perform-____","text":"If the documentation does not provide clear enough instruction, please see StackOverflow posts related to the datajoint tag or ask a new question tagging it appropriately. You may refer to our datajoint tag wiki for more details on its proper use.","title":"5a) Generally, how do I perform ____?"},{"location":"community/contribution/#5b-i-just-encountered-this-error-how-can-i-resolve-it","text":"Please see StackOverflow posts related to the datajoint tag or ask a new question tagging it appropriately. You may refer to our datajoint tag wiki for more details on its proper use.","title":"5b) I just encountered this error, how can I resolve it?"},{"location":"community/contribution/#5c-i-just-encountered-this-error-and-i-am-sure-it-is-a-bug-how-do-i-report-it","text":"Please file it under the issue tracker associated with the open-source software.","title":"5c) I just encountered this error and I am sure it is a bug, how do I report it?"},{"location":"community/contribution/#5d-i-have-an-idea-or-new-feature-request-how-do-i-submit-it","text":"Please file it under the issue tracker associated with the open-source software.","title":"5d) I have an idea or new feature request, how do I submit it?"},{"location":"community/contribution/#5e-i-am-curious-why-the-maintainers-choose-to-____-ie-questions-that-are-opinionated-in-nature-with-answers-that-some-might-disagree","text":"Please join the community on the DataJoint Slack and ask on the most relevant channel. There, you may engage directly with the maintainers for proper discourse.","title":"5e) I am curious why the maintainers choose to ____? i.e. questions that are \u2018opinionated\u2019 in nature with answers that some might disagree."},{"location":"community/contribution/#5f-what-is-the-timeline-or-roadmap-for-the-release-of-certain-supported-features","text":"Please refer to milestones and projects associated with the open-source software.","title":"5f) What is the timeline or roadmap for the release of certain supported features?"},{"location":"community/contribution/#5g-i-need-urgent-help-best-suited-for-live-debugging-how-can-i-reach-out-directly","text":"Please join the community on the DataJoint Slack and ask on the most relevant channel. Please bear in mind that as open-source community software, availability of the maintainers might be limited.","title":"5g) I need urgent help best suited for live debugging, how can I reach out directly?"},{"location":"community/events/","text":"Events \u00b6 Find us at the following workshops and conferences! DataJoint Office Hours \u00b6 The DataJoint open source team are offering monthly Office Hours ( see details here ). Sign up here ! Upcoming Workshops \u00b6 Senses in Motion Symposium - October 17, 2022 Society for Neuroscience - November 12-16, 2022 Past Events \u00b6 NeuroDataReHack Hackathon - October 3-5, 2022 Neuropixels and OpenScope Workshop - September 21-23, 2022 INCF Assembly - September 12-16, 2022 Research Workflows Workshop - September 6-8, 2022 NWB Hackathon User Days - July 24-27, 2022 NIH BRAIN Initiative Meeting - June 21-22, 2022 DataJoint Office Hours - May 20, 2022 MATLAB/Python interoperability. Video Link DataJoint Office Hours - April 27, 2022 Filepath handling, linking_module , and key management in make functions. UCL Neuropixels Course - October 19, 2021 INCF Neuroinformatics Training Week - August 30 - September 2, 2021 Session 1 Recording Session 2 Recording Session 3 Recording Session 4 Recording NYU \u2018FAIR Thee Well\u2019 Symposium - August 9-10, 2021 Sessions 1-3 Recordings Neuromatch Academy - July 29, 2021 Session 1 Recording Session 2 Recording","title":"Events"},{"location":"community/events/#events","text":"Find us at the following workshops and conferences!","title":"Events"},{"location":"community/events/#datajoint-office-hours","text":"The DataJoint open source team are offering monthly Office Hours ( see details here ). Sign up here !","title":"DataJoint Office Hours"},{"location":"community/events/#upcoming-workshops","text":"Senses in Motion Symposium - October 17, 2022 Society for Neuroscience - November 12-16, 2022","title":"Upcoming Workshops"},{"location":"community/events/#past-events","text":"NeuroDataReHack Hackathon - October 3-5, 2022 Neuropixels and OpenScope Workshop - September 21-23, 2022 INCF Assembly - September 12-16, 2022 Research Workflows Workshop - September 6-8, 2022 NWB Hackathon User Days - July 24-27, 2022 NIH BRAIN Initiative Meeting - June 21-22, 2022 DataJoint Office Hours - May 20, 2022 MATLAB/Python interoperability. Video Link DataJoint Office Hours - April 27, 2022 Filepath handling, linking_module , and key management in make functions. UCL Neuropixels Course - October 19, 2021 INCF Neuroinformatics Training Week - August 30 - September 2, 2021 Session 1 Recording Session 2 Recording Session 3 Recording Session 4 Recording NYU \u2018FAIR Thee Well\u2019 Symposium - August 9-10, 2021 Sessions 1-3 Recordings Neuromatch Academy - July 29, 2021 Session 1 Recording Session 2 Recording","title":"Past Events"},{"location":"community/licenses/","text":"Licenses \u00b6 The resources are distributed under the following licenses which are included in the respective repositories: DataJoint Python: LGPLv3 License DataJoint MATLAB: MIT License Pharus: MIT License DataJoint LabBook: MIT License DataJoint Sci-Viz: MIT License DataJoint Elements and Workflows: MIT License","title":"Licenses"},{"location":"community/licenses/#licenses","text":"The resources are distributed under the following licenses which are included in the respective repositories: DataJoint Python: LGPLv3 License DataJoint MATLAB: MIT License Pharus: MIT License DataJoint LabBook: MIT License DataJoint Sci-Viz: MIT License DataJoint Elements and Workflows: MIT License","title":"Licenses"},{"location":"community/support/","text":"Support \u00b6 We have a general policy for DataJoint open-source community engagement . General how-to or error question? Post on StackOverflow with the datajoint tag Bug report or feature request? Submit a GitHub issue to the relevant repository For open-ended discussions, join us on the DataJoint Slack DataJoint Office Hours The DataJoint open source team will be offering monthly Office Hours. These are public workshops on Zoom where we offer two half-hour sessions of free hands-on support to teams using DataJoint software. For each half-hour session, a team can sign up to work through their specific question. Teams who wish to receive this support can either share their workflow directly or work with DataJoint engineers to replicate the issue in a test environment. To be fair to the community, no team will be selected for support more than once per quarter. Sign up for Office Hours! For fully managed services, we invite you to visit the DataJoint Solutions page and request more information.","title":"Support"},{"location":"community/support/#support","text":"We have a general policy for DataJoint open-source community engagement . General how-to or error question? Post on StackOverflow with the datajoint tag Bug report or feature request? Submit a GitHub issue to the relevant repository For open-ended discussions, join us on the DataJoint Slack DataJoint Office Hours The DataJoint open source team will be offering monthly Office Hours. These are public workshops on Zoom where we offer two half-hour sessions of free hands-on support to teams using DataJoint software. For each half-hour session, a team can sign up to work through their specific question. Teams who wish to receive this support can either share their workflow directly or work with DataJoint engineers to replicate the issue in a test environment. To be fair to the community, no team will be selected for support more than once per quarter. Sign up for Office Hours! For fully managed services, we invite you to visit the DataJoint Solutions page and request more information.","title":"Support"},{"location":"community/partnerships/dandi/","text":"DANDI \u00b6 Sustainability Roadmap between DataJoint Elements and DANDI Archive \u00b6 Aim \u00b6 DataJoint Elements and The DANDI Archive (DANDI) are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems. Projects and Teams \u00b6 DataJoint \u00b6 DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com. Neurodata without Borders (NWB) \u00b6 DANDI - https://dandiarchive.org \u2014 is an archive for neurophysiology data, providing neuroscientists with a common platform to share, archive, and process data. The project is funded by the NIH grant R24 MH117295 and led by Dr. Satrajit S. Ghosh and Dr. Yaroslav O. Halchenko. The principal developers of DANDI are at the Massachusetts Institute of Technology, Dartmouth College, Catalyst Neuro, and Kitware. General Principles \u00b6 No obligation \u00b6 The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications. Coordinated Development \u00b6 The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools Points of Contact \u00b6 To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and DANDI. For 2022, the DataJoint Elements POC is Dr. Chris Brozdowski (cbroz@datajoint.com) For 2022, the DANDI POC is Dr.Satrajit Ghosh (satra@mit.edu) Annual Review \u00b6 To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available. Licensing \u00b6 The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and DANDI. Development Roadmap \u00b6 Mechanism to upload to DANDI - Completed 2022 - Element Interface DANDI module Documentation to upload to DANDI - Completed 2022 - Jupyter notebook","title":"DANDI"},{"location":"community/partnerships/dandi/#dandi","text":"","title":"DANDI"},{"location":"community/partnerships/dandi/#sustainability-roadmap-between-datajoint-elements-and-dandi-archive","text":"","title":"Sustainability Roadmap  between DataJoint Elements and DANDI Archive"},{"location":"community/partnerships/dandi/#aim","text":"DataJoint Elements and The DANDI Archive (DANDI) are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems.","title":"Aim"},{"location":"community/partnerships/dandi/#projects-and-teams","text":"","title":"Projects and Teams"},{"location":"community/partnerships/dandi/#datajoint","text":"DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.","title":"DataJoint"},{"location":"community/partnerships/dandi/#neurodata-without-borders-nwb","text":"DANDI - https://dandiarchive.org \u2014 is an archive for neurophysiology data, providing neuroscientists with a common platform to share, archive, and process data. The project is funded by the NIH grant R24 MH117295 and led by Dr. Satrajit S. Ghosh and Dr. Yaroslav O. Halchenko. The principal developers of DANDI are at the Massachusetts Institute of Technology, Dartmouth College, Catalyst Neuro, and Kitware.","title":"Neurodata without Borders (NWB)"},{"location":"community/partnerships/dandi/#general-principles","text":"","title":"General Principles"},{"location":"community/partnerships/dandi/#no-obligation","text":"The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.","title":"No obligation"},{"location":"community/partnerships/dandi/#coordinated-development","text":"The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools","title":"Coordinated Development"},{"location":"community/partnerships/dandi/#points-of-contact","text":"To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and DANDI. For 2022, the DataJoint Elements POC is Dr. Chris Brozdowski (cbroz@datajoint.com) For 2022, the DANDI POC is Dr.Satrajit Ghosh (satra@mit.edu)","title":"Points of Contact"},{"location":"community/partnerships/dandi/#annual-review","text":"To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.","title":"Annual Review"},{"location":"community/partnerships/dandi/#licensing","text":"The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and DANDI.","title":"Licensing"},{"location":"community/partnerships/dandi/#development-roadmap","text":"Mechanism to upload to DANDI - Completed 2022 - Element Interface DANDI module Documentation to upload to DANDI - Completed 2022 - Jupyter notebook","title":"Development Roadmap"},{"location":"community/partnerships/facemap/","text":"Facemap \u00b6 Sustainability Roadmap between DataJoint Elements and Facemap \u00b6 Aim \u00b6 DataJoint Elements and Facemap are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems. Projects and Teams \u00b6 DataJoint \u00b6 DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com. Facemap \u00b6 Facemap - https://github.com/MouseLand/facemap \u2014 is a pipeline for processing imaging data. The project is funded by HHMI Janelia Research Campus and led by Dr. Carsen Stringer and Atika Syeda. The principal developers of Facemap are at the Janelia Research Campus. General Principles \u00b6 No obligation \u00b6 The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications. Coordinated Development \u00b6 The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools Points of Contact \u00b6 To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and Facemap. For 2022, the DataJoint Elements POC is Dr. Tolga Dincer (tolga@datajoint.com) For 2022, the Facemap POC is Dr. Carsen Stringer (stringerc@janelia.hhmi.org) Annual Review \u00b6 To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available. Licensing \u00b6 The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and Facemap. Development Roadmap \u00b6 Mechanism to import Facemap results - Completed 2022 - Element Facemap Mechanism to run Facemap within DataJoint Elements - Completed 2022 - Element Facemap Tutorials on running DataJoint Element with Facemap - Under development Integration tests to verify loading Facemap data - Under development Integration tests to verify running Facemap - Under development Citation \u00b6 If you use Facemap please cite Stringer , Pachitariu , et al., Science 2019 in your publications.","title":"Facemap"},{"location":"community/partnerships/facemap/#facemap","text":"","title":"Facemap"},{"location":"community/partnerships/facemap/#sustainability-roadmap-between-datajoint-elements-and-facemap","text":"","title":"Sustainability Roadmap between DataJoint Elements and Facemap"},{"location":"community/partnerships/facemap/#aim","text":"DataJoint Elements and Facemap are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems.","title":"Aim"},{"location":"community/partnerships/facemap/#projects-and-teams","text":"","title":"Projects and Teams"},{"location":"community/partnerships/facemap/#datajoint","text":"DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.","title":"DataJoint"},{"location":"community/partnerships/facemap/#facemap_1","text":"Facemap - https://github.com/MouseLand/facemap \u2014 is a pipeline for processing imaging data. The project is funded by HHMI Janelia Research Campus and led by Dr. Carsen Stringer and Atika Syeda. The principal developers of Facemap are at the Janelia Research Campus.","title":"Facemap"},{"location":"community/partnerships/facemap/#general-principles","text":"","title":"General Principles"},{"location":"community/partnerships/facemap/#no-obligation","text":"The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.","title":"No obligation"},{"location":"community/partnerships/facemap/#coordinated-development","text":"The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools","title":"Coordinated Development"},{"location":"community/partnerships/facemap/#points-of-contact","text":"To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and Facemap. For 2022, the DataJoint Elements POC is Dr. Tolga Dincer (tolga@datajoint.com) For 2022, the Facemap POC is Dr. Carsen Stringer (stringerc@janelia.hhmi.org)","title":"Points of Contact"},{"location":"community/partnerships/facemap/#annual-review","text":"To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.","title":"Annual Review"},{"location":"community/partnerships/facemap/#licensing","text":"The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and Facemap.","title":"Licensing"},{"location":"community/partnerships/facemap/#development-roadmap","text":"Mechanism to import Facemap results - Completed 2022 - Element Facemap Mechanism to run Facemap within DataJoint Elements - Completed 2022 - Element Facemap Tutorials on running DataJoint Element with Facemap - Under development Integration tests to verify loading Facemap data - Under development Integration tests to verify running Facemap - Under development","title":"Development Roadmap"},{"location":"community/partnerships/facemap/#citation","text":"If you use Facemap please cite Stringer , Pachitariu , et al., Science 2019 in your publications.","title":"Citation"},{"location":"community/partnerships/incf/","text":"INCF \u00b6 DataJoint is a company member of INCF .","title":"INCF"},{"location":"community/partnerships/incf/#incf","text":"DataJoint is a company member of INCF .","title":"INCF"},{"location":"community/partnerships/nwb/","text":"NWB \u00b6 Integrations between DataJoint Elements and Neurodata Without Borders \u00b6 Aim \u00b6 DataJoint Elements and Neurodata Without Borders (NWB) are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems. Projects and Teams \u00b6 DataJoint \u00b6 DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com. Neurodata without Borders (NWB) \u00b6 NWB - https://www.nwb.org \u2014 is a data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build analysis tools for neurophysiology data. The project is funded by the NIH grant U24 NS120057 and led by Dr. Oliver Rubel (Lawrence Berkeley National Laboratory) and Dr. Benjamin Dichter (Catalyst Neuro). The principal developers of NWB are the Lawrence Berkeley National Laboratory and Catalyst Neuro. General Principles \u00b6 No obligation \u00b6 The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications. Coordinated Development \u00b6 The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools Points of Contact \u00b6 To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and NWB. For 2022, the DataJoint Elements POC is Dr. Chris Brozdowski (cbroz@datajoint.com) For 2022, the NWB POC is Dr. Ryan Ly (Lawrence Berkeley National Laboratory) Annual Review \u00b6 To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available. Licensing \u00b6 The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements workflows and NWB utilities.","title":"NWB"},{"location":"community/partnerships/nwb/#nwb","text":"","title":"NWB"},{"location":"community/partnerships/nwb/#integrations-between-datajoint-elements-and-neurodata-without-borders","text":"","title":"Integrations between DataJoint Elements and Neurodata Without Borders"},{"location":"community/partnerships/nwb/#aim","text":"DataJoint Elements and Neurodata Without Borders (NWB) are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems.","title":"Aim"},{"location":"community/partnerships/nwb/#projects-and-teams","text":"","title":"Projects and Teams"},{"location":"community/partnerships/nwb/#datajoint","text":"DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.","title":"DataJoint"},{"location":"community/partnerships/nwb/#neurodata-without-borders-nwb","text":"NWB - https://www.nwb.org \u2014 is a data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build analysis tools for neurophysiology data. The project is funded by the NIH grant U24 NS120057 and led by Dr. Oliver Rubel (Lawrence Berkeley National Laboratory) and Dr. Benjamin Dichter (Catalyst Neuro). The principal developers of NWB are the Lawrence Berkeley National Laboratory and Catalyst Neuro.","title":"Neurodata without Borders (NWB)"},{"location":"community/partnerships/nwb/#general-principles","text":"","title":"General Principles"},{"location":"community/partnerships/nwb/#no-obligation","text":"The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.","title":"No obligation"},{"location":"community/partnerships/nwb/#coordinated-development","text":"The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools","title":"Coordinated Development"},{"location":"community/partnerships/nwb/#points-of-contact","text":"To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and NWB. For 2022, the DataJoint Elements POC is Dr. Chris Brozdowski (cbroz@datajoint.com) For 2022, the NWB POC is Dr. Ryan Ly (Lawrence Berkeley National Laboratory)","title":"Points of Contact"},{"location":"community/partnerships/nwb/#annual-review","text":"To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.","title":"Annual Review"},{"location":"community/partnerships/nwb/#licensing","text":"The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements workflows and NWB utilities.","title":"Licensing"},{"location":"community/partnerships/suite2p/","text":"Suite2p \u00b6 Sustainability Roadmap between DataJoint Elements and Suite2p \u00b6 Aim \u00b6 DataJoint Elements and Suite2p are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems. Projects and Teams \u00b6 DataJoint \u00b6 DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com. Suite2p \u00b6 Suite2p \u2014 https://www.suite2p.org \u2014 is a pipeline for processing calcium imaging data. The project is funded by HHMI Janelia Research Campus and led by Dr. Carsen Stringer and Dr. Marius Pachitariu. The principal developers of Suite2p are at the Janelia Research Campus. General Principles \u00b6 No obligation \u00b6 The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications. Coordinated Development \u00b6 The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools Points of Contact \u00b6 To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and Suite2p. For 2022, the DataJoint Elements POC is Dr. Tolga Dincer (tolga@datajoint.com) For 2022, the Suite2p POC is Dr. Carsen Stringer (stringerc@janelia.hhmi.org) Annual Review \u00b6 To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available. Licensing \u00b6 The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and Suite2p. Development Roadmap \u00b6 Mechanism to import Suite2p results - Completed 2021 - Element Interface Suite2p module Mechanism to run Suite2p within DataJoint Element - Completed 2022 - Element Calcium Imaging Tutorials on running DataJoint Element with Suite2p - Completed 2021 - Workflow Calcium Imaging Jupyter notebooks Integration tests to verify loading Suite2p data - Completed 2021 - Pytests Integration tests to verify running Suite2p - Completed 2022 - Pytests Citation \u00b6 If you use Suite2p please cite Pachitariu et al., bioRxiv 2017 in your publications.","title":"Suite2p"},{"location":"community/partnerships/suite2p/#suite2p","text":"","title":"Suite2p"},{"location":"community/partnerships/suite2p/#sustainability-roadmap-between-datajoint-elements-and-suite2p","text":"","title":"Sustainability Roadmap between DataJoint Elements and Suite2p"},{"location":"community/partnerships/suite2p/#aim","text":"DataJoint Elements and Suite2p are two neuroinformatics initiatives in active development. The projects develop independently yet they have complementary aims and overlapping user communities. This document establishes key processes for coordinating development and communications in order to promote integration and interoperability across the two ecosystems.","title":"Aim"},{"location":"community/partnerships/suite2p/#projects-and-teams","text":"","title":"Projects and Teams"},{"location":"community/partnerships/suite2p/#datajoint","text":"DataJoint Elements \u2014 https://datajoint.com/docs/elements/ \u2014 is a collection of open-source reference database schemas and analysis workflows for neurophysiology experiments, supported by DataJoint \u2014 https://datajoint.com/docs/core/ \u2014 an open-source software framework. The project is funded by the NIH grant U24 NS116470 and led by Dr. Dimitri Yatsenko. The principal developer of DataJoint Elements and the DataJoint framework is the company DataJoint \u2014 https://datajoint.com.","title":"DataJoint"},{"location":"community/partnerships/suite2p/#suite2p_1","text":"Suite2p \u2014 https://www.suite2p.org \u2014 is a pipeline for processing calcium imaging data. The project is funded by HHMI Janelia Research Campus and led by Dr. Carsen Stringer and Dr. Marius Pachitariu. The principal developers of Suite2p are at the Janelia Research Campus.","title":"Suite2p"},{"location":"community/partnerships/suite2p/#general-principles","text":"","title":"General Principles"},{"location":"community/partnerships/suite2p/#no-obligation","text":"The developers of the two ecosystems acknowledge that this roadmap document creates no contractual relationship between them but they agree to work together in the spirit of partnership to ensure that there is a united, visible, and responsive leadership and to demonstrate administrative and managerial commitment to coordinate development and communications.","title":"No obligation"},{"location":"community/partnerships/suite2p/#coordinated-development","text":"The two projects will coordinate their development approaches to ensure maximum interoperability. This includes: coordinated use of terminology and nomenclatures support for testing infrastructure: unit testing and integration testing a coordinated software release process and versioning coordinated resolution of issues arising from joint use of the two tools","title":"Coordinated Development"},{"location":"community/partnerships/suite2p/#points-of-contact","text":"To achieve the aims of coordinated development, both projects appoint a primary point of contact (POC) to respond to questions relating to the integration and interoperability of DataJoint Elements and Suite2p. For 2022, the DataJoint Elements POC is Dr. Tolga Dincer (tolga@datajoint.com) For 2022, the Suite2p POC is Dr. Carsen Stringer (stringerc@janelia.hhmi.org)","title":"Points of Contact"},{"location":"community/partnerships/suite2p/#annual-review","text":"To achieve the aims of coordinated development, the principal developers conduct a joint annual review of this roadmap document to ensure that the two programs are well integrated and not redundant. The contents and resolutions of the review will be made publicly available.","title":"Annual Review"},{"location":"community/partnerships/suite2p/#licensing","text":"The two parties ensure that relevant software components are developed under licenses that avoid any hindrance to integration and interoperability between DataJoint Elements and Suite2p.","title":"Licensing"},{"location":"community/partnerships/suite2p/#development-roadmap","text":"Mechanism to import Suite2p results - Completed 2021 - Element Interface Suite2p module Mechanism to run Suite2p within DataJoint Element - Completed 2022 - Element Calcium Imaging Tutorials on running DataJoint Element with Suite2p - Completed 2021 - Workflow Calcium Imaging Jupyter notebooks Integration tests to verify loading Suite2p data - Completed 2021 - Pytests Integration tests to verify running Suite2p - Completed 2022 - Pytests","title":"Development Roadmap"},{"location":"community/partnerships/suite2p/#citation","text":"If you use Suite2p please cite Pachitariu et al., bioRxiv 2017 in your publications.","title":"Citation"},{"location":"concepts/mantra/","text":"Mantra \u00b6 The DataJoint Mantra consists of three main objectives: Simplify your queries through an intuitive query language . Make automated, reproducible computation by integrating computation with the data model. Ensure validity of your data through referential integrity . Query Language \u00b6 Writing good, optimized SQL queries can be difficult and often becomes a barrier for individuals lacking experience in computer science and programming. That said, we don't feel this should discourage the use of databases. Databases help to structure our daily lives which streamlines the time required to glean insights and build robust applications from truth. SQL is powerful but requires practice which we feel is the real fault in the language. To address this, the DataJoint query language serves as a query builder and optimizer for SQL . It leverages the stack's own operator precedence and combines it with both operator overloading and SQL algebra to achieve a more intuitive experience. Additionally, interoperability between Python and MATLAB is crucial due to the diversity of tools available to scientists. So much so that this is a guiding principle in FAIR . Case in point, here is a comparison of equivalent queries: SQL SELECT * FROM ` shapes ` . ` rectangle ` NATURAL JOIN ` shapes ` . ` area ` WHERE ( ( ` shape_area `= 8 ) AND ( ` shape_height `= 2 ) ); DataJoint (Python) Rectangle * Area & dict ( shape_height = 2 , shape_area = 8 ) DataJoint (MATLAB) shapes . Rectangle * shapes . Area & struct ( 'shape_height' , 2 , 'shape_area' , 8 ) Reproducible Computation \u00b6 Reproducibility is a key concept within the scientific community since research is largely conducted, shared, and reviewed in the public domain. This is necessary to independently validate discoveries and have others support new findings. Such a practice is well advocated in the scientific community as open science . Yet, reliably reproducing computed results of others has proven difficult since there are many factors that affect the determinism of a process e.g. hardware, software environment, scripts, input data, seeding, etc. DataJoint pipelines address these challenges by allowing computation to be defined such that they are associated with an entity. Drawing relationships between many entities we can create a DAG that describes a compute workflow as an entity-relationship model . For instance, an entity such as Area could represent the computed value of a parent entity, Rectangle . Therefore, we feel it should be reasonable when defining Area to include the specification of a computation that automates how Area is generated based on relation to Rectangle . Referential Integrity \u00b6 Referential integrity is the concept of keeping all your data consistent and up-to-date. The goal is to ensure data pipelines always reflect the truth of how data was created. In the realm of databases, entities can be related to one another through foreign keys . However, our opinionated view is that foreign keys on primary keys should enforce the contraint. What this means is that our data model always reflects the truth. When a parent entity is removed, all child computed values will also be removed since they no longer have meaning without the subject. There is not a clear way to reproduce the results otherwise. An important consequence to note is that deletes take longer as a result since they must be cascaded down to all the descendants. We believe this to be a feature as it is the behavior most inline with typical expectations. Deletes should be done cautiously.","title":"Mantra"},{"location":"concepts/mantra/#mantra","text":"The DataJoint Mantra consists of three main objectives: Simplify your queries through an intuitive query language . Make automated, reproducible computation by integrating computation with the data model. Ensure validity of your data through referential integrity .","title":"Mantra"},{"location":"concepts/mantra/#query-language","text":"Writing good, optimized SQL queries can be difficult and often becomes a barrier for individuals lacking experience in computer science and programming. That said, we don't feel this should discourage the use of databases. Databases help to structure our daily lives which streamlines the time required to glean insights and build robust applications from truth. SQL is powerful but requires practice which we feel is the real fault in the language. To address this, the DataJoint query language serves as a query builder and optimizer for SQL . It leverages the stack's own operator precedence and combines it with both operator overloading and SQL algebra to achieve a more intuitive experience. Additionally, interoperability between Python and MATLAB is crucial due to the diversity of tools available to scientists. So much so that this is a guiding principle in FAIR . Case in point, here is a comparison of equivalent queries: SQL SELECT * FROM ` shapes ` . ` rectangle ` NATURAL JOIN ` shapes ` . ` area ` WHERE ( ( ` shape_area `= 8 ) AND ( ` shape_height `= 2 ) ); DataJoint (Python) Rectangle * Area & dict ( shape_height = 2 , shape_area = 8 ) DataJoint (MATLAB) shapes . Rectangle * shapes . Area & struct ( 'shape_height' , 2 , 'shape_area' , 8 )","title":"Query Language"},{"location":"concepts/mantra/#reproducible-computation","text":"Reproducibility is a key concept within the scientific community since research is largely conducted, shared, and reviewed in the public domain. This is necessary to independently validate discoveries and have others support new findings. Such a practice is well advocated in the scientific community as open science . Yet, reliably reproducing computed results of others has proven difficult since there are many factors that affect the determinism of a process e.g. hardware, software environment, scripts, input data, seeding, etc. DataJoint pipelines address these challenges by allowing computation to be defined such that they are associated with an entity. Drawing relationships between many entities we can create a DAG that describes a compute workflow as an entity-relationship model . For instance, an entity such as Area could represent the computed value of a parent entity, Rectangle . Therefore, we feel it should be reasonable when defining Area to include the specification of a computation that automates how Area is generated based on relation to Rectangle .","title":"Reproducible Computation"},{"location":"concepts/mantra/#referential-integrity","text":"Referential integrity is the concept of keeping all your data consistent and up-to-date. The goal is to ensure data pipelines always reflect the truth of how data was created. In the realm of databases, entities can be related to one another through foreign keys . However, our opinionated view is that foreign keys on primary keys should enforce the contraint. What this means is that our data model always reflects the truth. When a parent entity is removed, all child computed values will also be removed since they no longer have meaning without the subject. There is not a clear way to reproduce the results otherwise. An important consequence to note is that deletes take longer as a result since they must be cascaded down to all the descendants. We believe this to be a feature as it is the behavior most inline with typical expectations. Deletes should be done cautiously.","title":"Referential Integrity"},{"location":"concepts/query-lang/datatypes/","text":"Datatypes \u00b6 Throughout the DataJoint ecosystem, there are several datatypes that are used to define tables with cross-platform support i.e. Python, MATLAB. It is important to understand these types as they can have implications in the queries you form and the capacity of their storage. Standard Types \u00b6 These types are largely wrappers around existing types in the current query backend for data pipelines . Datatype Description Size Example int integer 4 bytes 8 Unique Types \u00b6 Datatype Description Size Example uuid a unique GUID value 16 bytes 6ed5ed09-e69c-466f-8d06-a5afbf273e61","title":"Datatypes"},{"location":"concepts/query-lang/datatypes/#datatypes","text":"Throughout the DataJoint ecosystem, there are several datatypes that are used to define tables with cross-platform support i.e. Python, MATLAB. It is important to understand these types as they can have implications in the queries you form and the capacity of their storage.","title":"Datatypes"},{"location":"concepts/query-lang/datatypes/#standard-types","text":"These types are largely wrappers around existing types in the current query backend for data pipelines . Datatype Description Size Example int integer 4 bytes 8","title":"Standard Types"},{"location":"concepts/query-lang/datatypes/#unique-types","text":"Datatype Description Size Example uuid a unique GUID value 16 bytes 6ed5ed09-e69c-466f-8d06-a5afbf273e61","title":"Unique Types"},{"location":"concepts/ref-integrity/query-backend/","text":"Query Backend \u00b6 Currently, data pipelines use MySQL server for its query backend. The following are some important topics to maintain a healthy system: Access Control Optimal Server Configuration Maintenance Guidelines","title":"Query Backend"},{"location":"concepts/ref-integrity/query-backend/#query-backend","text":"Currently, data pipelines use MySQL server for its query backend. The following are some important topics to maintain a healthy system: Access Control Optimal Server Configuration Maintenance Guidelines","title":"Query Backend"},{"location":"elements/","text":"DataJoint Elements for Neurophysiology \u00b6 DataJoint Elements provides an efficient approach for neuroscience labs to create and manage scientific data workflows : the complex multi-step methods for data collection, preparation, processing, analysis, and modeling that researchers must perform in the course of an experimental study. Elements are a collection of curated modules for assembling workflows for several modalities of neurophysiology experiments and are designed for ease of integration into diverse custom workflows. This work is derived from the developments in leading neuroscience projects and uses the DataJoint API for defining, deploying, and sharing their data workflows. An overview of the principles of DataJoint workflows and the goals of DataJoint Elements are described in the position paper \"DataJoint Elements: Data Workflows for Neurophysiology\" . Below are the projects that make up the family of open-source DataJoint Elements: Element Calcium Imaging A data pipeline for calcium imaging microscopy. Getting started Element Array Electrophysiology A data pipeline for Neuropixels probes. Getting started Element Electrode Localization A data pipeline for electrode localization of Neuropixels probes. Getting started Element Miniscope A data pipeline for miniscope calcium imaging. Getting started Element DeepLabCut A data pipeline for pose estimation with DeepLabCut. Getting started Element Facemap A data pipeline for pose estimation with Facemap. Getting started Element Visual Stimulus A data pipeline for visual stimulation with Psychtoolbox. Getting started Element Lab A data pipeline for lab management. Getting started Element Animal A data pipeline for subject management. Getting started Element Session A data pipeline for session management. Getting started Element Event A data pipeline for event- and trial-based experiments. Getting started","title":"Overview"},{"location":"elements/#datajoint-elements-for-neurophysiology","text":"DataJoint Elements provides an efficient approach for neuroscience labs to create and manage scientific data workflows : the complex multi-step methods for data collection, preparation, processing, analysis, and modeling that researchers must perform in the course of an experimental study. Elements are a collection of curated modules for assembling workflows for several modalities of neurophysiology experiments and are designed for ease of integration into diverse custom workflows. This work is derived from the developments in leading neuroscience projects and uses the DataJoint API for defining, deploying, and sharing their data workflows. An overview of the principles of DataJoint workflows and the goals of DataJoint Elements are described in the position paper \"DataJoint Elements: Data Workflows for Neurophysiology\" . Below are the projects that make up the family of open-source DataJoint Elements: Element Calcium Imaging A data pipeline for calcium imaging microscopy. Getting started Element Array Electrophysiology A data pipeline for Neuropixels probes. Getting started Element Electrode Localization A data pipeline for electrode localization of Neuropixels probes. Getting started Element Miniscope A data pipeline for miniscope calcium imaging. Getting started Element DeepLabCut A data pipeline for pose estimation with DeepLabCut. Getting started Element Facemap A data pipeline for pose estimation with Facemap. Getting started Element Visual Stimulus A data pipeline for visual stimulation with Psychtoolbox. Getting started Element Lab A data pipeline for lab management. Getting started Element Animal A data pipeline for subject management. Getting started Element Session A data pipeline for session management. Getting started Element Event A data pipeline for event- and trial-based experiments. Getting started","title":"DataJoint Elements for Neurophysiology"},{"location":"elements/concepts/","text":"Concepts \u00b6 The following conventions describe the DataJoint Python API implementation. DataJoint Schemas \u00b6 The DataJoint Python API allows creating database schemas , which are namespaces for collections of related tables. The following commands declare a new schema and create the object named schema to reference the database schema. import datajoint as dj schema = dj . schema ( '<schema_name>' ) We follow the convention of having only one schema defined per Python module. Then such a module becomes a DataJoint schema comprising a Python module with a corresponding database schema . The module's schema object is then used as the decorator for classes that define tables in the database. Elements \u00b6 An Element is a software package defining one or more DataJoint schemas serving a particular purpose. By convention, such packages are hosted in individual GitHub repositories. For example, Element element_calcium_imaging is hosted at https://github.com/datajoint/element-calcium-imaging and contains two DataJoint schemas: scan and imaging . YouTube Tutorials \u00b6 The following YouTube videos provide information on basic design principles and file organization. Why neuroscientists should use relational databases compared to traditional file heirarchies. Quickstart Guide including terminology, and how to read DataJoint Diagrams and DataJoint Python table definitions. Intro to the Element and Workflow files for an overview of the respective GitHub repositories. Overview of upstream Elements to ingest and explore Lab, Animal, and Session metadata. Note: Some videos feature outdated versions of the respective GitHub repositories. For the most updated information, check the documentation page for the corresponding Element. Deferred schemas \u00b6 A deferred schema is one in which the name of the database schema name is not specified. This module does not declare schema and tables upon import. Instead, they are declared by calling schema.activate('<schema_name>') after import. By convention, all modules corresponding to deferred schema must declare the function activate which in turn calls schema.activate . Thus, Element modules begin with: import datajoint as dj schema = dj . schema () def activate ( schema_name ): schema . activate ( schema_name ) However, many activate functions perform other work associated with activating the schema such as activating other schemas upstream. Linking Module \u00b6 To make the code more modular with fewer dependencies, Element modules do not import upstream schemas directly. Instead, all required classes and functions must be defined in a linking_module and passed to the module's activate function. By keeping all upstream requirements in the linking module, all Elements can be activated as part of any larger pipeline. For instance, the Scan module receives its required functions from the linking module passed into the module's activate function. See the corresponding workflow for an example of how the linking module is passed into the Element's module.","title":"Concepts"},{"location":"elements/concepts/#concepts","text":"The following conventions describe the DataJoint Python API implementation.","title":"Concepts"},{"location":"elements/concepts/#datajoint-schemas","text":"The DataJoint Python API allows creating database schemas , which are namespaces for collections of related tables. The following commands declare a new schema and create the object named schema to reference the database schema. import datajoint as dj schema = dj . schema ( '<schema_name>' ) We follow the convention of having only one schema defined per Python module. Then such a module becomes a DataJoint schema comprising a Python module with a corresponding database schema . The module's schema object is then used as the decorator for classes that define tables in the database.","title":"DataJoint Schemas"},{"location":"elements/concepts/#elements","text":"An Element is a software package defining one or more DataJoint schemas serving a particular purpose. By convention, such packages are hosted in individual GitHub repositories. For example, Element element_calcium_imaging is hosted at https://github.com/datajoint/element-calcium-imaging and contains two DataJoint schemas: scan and imaging .","title":"Elements"},{"location":"elements/concepts/#youtube-tutorials","text":"The following YouTube videos provide information on basic design principles and file organization. Why neuroscientists should use relational databases compared to traditional file heirarchies. Quickstart Guide including terminology, and how to read DataJoint Diagrams and DataJoint Python table definitions. Intro to the Element and Workflow files for an overview of the respective GitHub repositories. Overview of upstream Elements to ingest and explore Lab, Animal, and Session metadata. Note: Some videos feature outdated versions of the respective GitHub repositories. For the most updated information, check the documentation page for the corresponding Element.","title":"YouTube Tutorials"},{"location":"elements/concepts/#deferred-schemas","text":"A deferred schema is one in which the name of the database schema name is not specified. This module does not declare schema and tables upon import. Instead, they are declared by calling schema.activate('<schema_name>') after import. By convention, all modules corresponding to deferred schema must declare the function activate which in turn calls schema.activate . Thus, Element modules begin with: import datajoint as dj schema = dj . schema () def activate ( schema_name ): schema . activate ( schema_name ) However, many activate functions perform other work associated with activating the schema such as activating other schemas upstream.","title":"Deferred schemas"},{"location":"elements/concepts/#linking-module","text":"To make the code more modular with fewer dependencies, Element modules do not import upstream schemas directly. Instead, all required classes and functions must be defined in a linking_module and passed to the module's activate function. By keeping all upstream requirements in the linking module, all Elements can be activated as part of any larger pipeline. For instance, the Scan module receives its required functions from the linking module passed into the module's activate function. See the corresponding workflow for an example of how the linking module is passed into the Element's module.","title":"Linking Module"},{"location":"elements/developer-instructions/","text":"Developer instructions \u00b6 Development mode installation \u00b6 We recommend doing development work in a conda environment. For information on setting up conda for the first time, see this article . This method allows you to modify the source code for example DataJoint workflows (e.g. workflow-array-ephys ) and their dependencies (e.g., element-array-ephys ). Launch a new terminal and change directory to where you want to clone the repositories (e.g., bash cd ~/Projects ) Clone the relevant workflow and refer to the requirements.txt in the workflow for the list of Elements to clone and install as editable. You will also need to install element-interface deps =( \"lab\" \"animal\" \"session\" \"interface\" \"<others>\" ) for repo in $deps # clone each do git clone https://github.com/datajoint/element- $repo done for repo in $( ls -d ./ { element,workflow } * ) # editable install do pip install -e ./ $repo done Optionally drop all schemas \u00b6 If you need to drop all schemas to start fresh, you'll need to do following the dependency order. Refer to the workflow's notebook ( notebooks/06-drop-optional.ipynb ) for the drop order. Run integration tests \u00b6 Download the test dataset to your local machine. Note the directory where the dataset is saved (e.g. /tmp/testset ). Create an .env file within the docker directory with the following content. Replace /tmp/testset with the directory where you have the test dataset downloaded. TEST_DATA_DIR=/tmp/testset If testing an unreleased version of the element or your fork of an element or the workflow , within the Dockerfile uncomment the lines from the different options presented. This will allow you to install the repositories of interest and run the integration tests on those packages. Be sure that the element package version matches the version in the requirements.txt of the workflow . Run the Docker container. docker-compose -f ./docker/docker-compose-test.yaml up --build Jupytext \u00b6 We maintain .py script copies of all didactic notebooks to facilitate the GitHub review process. From the main workflow directory, we recommend the following command to generate these copies. You may wish to save this as an alias in your .bash_profile . Note that the jupytext sync features may cause issues with the original notebooks. ```bash pip install jupytext jupytext --to py notebooks/0*ipynb; mv notebooks/*py notebooks/py_scripts ```","title":"Developer Guide"},{"location":"elements/developer-instructions/#developer-instructions","text":"","title":"Developer instructions"},{"location":"elements/developer-instructions/#development-mode-installation","text":"We recommend doing development work in a conda environment. For information on setting up conda for the first time, see this article . This method allows you to modify the source code for example DataJoint workflows (e.g. workflow-array-ephys ) and their dependencies (e.g., element-array-ephys ). Launch a new terminal and change directory to where you want to clone the repositories (e.g., bash cd ~/Projects ) Clone the relevant workflow and refer to the requirements.txt in the workflow for the list of Elements to clone and install as editable. You will also need to install element-interface deps =( \"lab\" \"animal\" \"session\" \"interface\" \"<others>\" ) for repo in $deps # clone each do git clone https://github.com/datajoint/element- $repo done for repo in $( ls -d ./ { element,workflow } * ) # editable install do pip install -e ./ $repo done","title":"Development mode installation"},{"location":"elements/developer-instructions/#optionally-drop-all-schemas","text":"If you need to drop all schemas to start fresh, you'll need to do following the dependency order. Refer to the workflow's notebook ( notebooks/06-drop-optional.ipynb ) for the drop order.","title":"Optionally drop all schemas"},{"location":"elements/developer-instructions/#run-integration-tests","text":"Download the test dataset to your local machine. Note the directory where the dataset is saved (e.g. /tmp/testset ). Create an .env file within the docker directory with the following content. Replace /tmp/testset with the directory where you have the test dataset downloaded. TEST_DATA_DIR=/tmp/testset If testing an unreleased version of the element or your fork of an element or the workflow , within the Dockerfile uncomment the lines from the different options presented. This will allow you to install the repositories of interest and run the integration tests on those packages. Be sure that the element package version matches the version in the requirements.txt of the workflow . Run the Docker container. docker-compose -f ./docker/docker-compose-test.yaml up --build","title":"Run integration tests"},{"location":"elements/developer-instructions/#jupytext","text":"We maintain .py script copies of all didactic notebooks to facilitate the GitHub review process. From the main workflow directory, we recommend the following command to generate these copies. You may wish to save this as an alias in your .bash_profile . Note that the jupytext sync features may cause issues with the original notebooks. ```bash pip install jupytext jupytext --to py notebooks/0*ipynb; mv notebooks/*py notebooks/py_scripts ```","title":"Jupytext"},{"location":"elements/user-instructions/","text":"User setup instructions \u00b6 Instructions for workflows created with the DataJoint Elements The following document describes the steps to setup a development environment so that you can use the DataJoint Elements to build and run a workflow on your local machine. The DataJoint Elements can be combined together to create a workflow that matches your experimental setup. We have created example workflows (e.g. workflow-array-ephys , workflow-calcium-imaging ) for your reference. In this tutorial we will install these example DataJoint workflows. These instructions can be adapted for your custom DataJoint workflow. There are several ways to create a development environment. Here we will discuss one method in detail, and will highlight other methods along the way. If you have already set up certain components, feel free to skip those sections. You will need administrative privileges on your system for the following setup instructions. System architecture \u00b6 The above diagram describes the general components for a local DataJoint development environment. Install an integrated development environment \u00b6 DataJoint development and use can be done with a plain text editor in the terminal. However, an integrated development environment (IDE) can improve your experience. Several IDEs are available. In this setup example, we will use Microsoft's Visual Studio Code. Installation instructions here Install a relational database \u00b6 A key feature of DataJoint is the ability to connect with a database server from a scientific programming environment (i.e., Python or MATLAB) so that your experimental data can be stored in the database and downloaded from the database. There are several options if you would like to install a local relational database server. If using the Docker and Compose files that come with each workflow (e.g. workflow-calcium-imaging ), these are preconfigured with a Docker container that hosts a MySQL server. Docker image for MySQL server configured for use with DataJoint Install MariaDB server Alternatively, for the simplicity of this tutorial you can use the DataJoint tutorial database located at tutorial-db.datajoint.io which has already been configured. The credentials to log in to the tutorial database are the same as for DataJoint Accounts . Please note that the tutorial database should not be used for your experimental analysis as the storage is not persistent. Install a version control system \u00b6 Git is an open-source, distributed version control system for collaborating with software development. GitHub is a platform that hosts projects managed with Git. As the example DataJoint workflows are hosted on GitHub, we will use Git to clone (i.e., download) this repository. For your own DataJoint workflow development we recommended that you use Git and GitHub for collaboration. Many systems come preinstalled with Git. You can test if Git is already installed by typing git in a terminal window. If Git is not installed on your system, Install Git . Install a virtual environment \u00b6 A virtual environment allows you to install the packages required for a specific project within an isolated environment on your computer. It is highly recommended (though not strictly required) to create a virtual environment to run the workflow. Conda and virtualenv are virtual environment managers and you can use either option. Below you will find instructions for conda. Miniconda is a minimal installer for conda. Follow the installer instructions for your operating system. You may need to add the Miniconda directory to the PATH environment variable First locate the Miniconda directory Then modify and run the following command export PATH = \"<absolute-path-to-miniconda-directory>/bin: $PATH \" Create a new conda environment conda create -n <environment_name> python = <version> Example command to create a conda environment conda create -n workflow-array-ephys python = 3 .8.11 Activate the conda environment conda activate <environment_name> Install Jupyter Notebook packages \u00b6 Install the following, if you are using Jupyter Notebook. conda install jupyter ipykernel nb_conda_kernels Install the following, for dj.Diagram to render. conda install graphviz python-graphviz pydotplus Clone and install the relevant repository \u00b6 In a terminal window and change the directory to where you want to clone the repository cd ~/Projects Clone the relevant repository, often one of the workflows git clone https://github.com/datajoint/<repository> Change into the cloned directory cd <repository> From the root of the cloned repository directory. Note: the -e flag, which will will install this repository in editable mode, in case there's a need to modify the code (e.g. the workflow pipeline.py or paths.py scripts). If no such modification is required, using pip install . is sufficient. pip install -e . Install element-interface , which contains scripts to load data for many of our Elements, and all workflows pip install \"element-interface @ git+https://github.com/datajoint/element-interface\" Items specific to workflow-calcium-imaging Click to expand details element-interface can also be used to install packages used for reading acquired data (e.g., scanreader ) and running analyses (e.g., CaImAn ). Install element-interface with scanreader pip install \"element-interface[scanreader] @ git+https://github.com/datajoint/element-interface\" Install element-interface with sbxreader pip install \"element-interface[sbxreader] @ git+https://github.com/datajoint/element-interface\" Install element-interface with Suite2p pip install \"element-interface[suite2p] @ git+https://github.com/datajoint/element-interface\" Install element-interface with CaImAn requires two separate commands pip install \"element-interface[caiman_requirements] @ git+https://github.com/datajoint/element-interface\" pip install \"element-interface[caiman] @ git+https://github.com/datajoint/element-interface\" Example element-interface installation with multiple packages bash pip install \"element-interface[caiman_requirements] @ git+https://github.com/datajoint/element-interface\" pip install \"element-interface[scanreader,sbxreader,suite2p,caiman] @ git+https://github.com/datajoint/element-interface\" Set up a connection to the database server \u00b6 One way to set up a connection to the database server with DataJoint is to create a local configuration file (i.e., dj_local_conf.json ) at the root of the repository folder, with the following template: { \"database.host\" : \"<hostname>\" , \"database.user\" : \"<username>\" , \"database.password\" : \"<password>\" , \"loglevel\" : \"INFO\" , \"safemode\" : true , \"display.limit\" : 7 , \"display.width\" : 14 , \"display.show_tuple_count\" : true , \"custom\" : { \"database.prefix\" : \"<username_>\" } } Specify the database's hostname , username , and password . If using the Docker image for MySQL server configured for use with DataJoint then the hostname will be localhost . If using the tutorial database, the hostname will be tutorial-db.datajoint.io . And the username and password will be the credentials for your DataJoint account . Specify a database.prefix which will be the prefix for your schema names. For a local setup, it can be set as you see fit (e.g., neuro_ ). For the tutorial-db database, you will use your DataJoint username. Specific workflows will require additional information in the custom field, including paths to data directories, following the convention described in the directory structure section . If multiple root directories exist, include all in the relevant json array. + workflow-array-ephys Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"ephys_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details> + workflow-calcium-imaging Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"imaging_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details> + workflow-miniscope Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"miniscope_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details> + workflow-deeplabcut Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"dlc_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details> Setup complete \u00b6 At this point the setup of this workflow is complete. Download example data \u00b6 We provide example data to use with the example DataJoint workflows. The data is hosted on DataJoint's Archive which is an AWS storage and can be download with djarchive-client . Install djarchive-client pip install git+https://github.com/datajoint/djarchive-client.git In your python interpreter, import the client import djarchive_client client = djarchive_client . client () Browse the available datasets list ( client . datasets ()) Each datasets has different versions associated with the version of the workflow package. Browse the revisions. python list(client.revisions()) Prepare a directory to store the download data, for example in /tmp mkdir /tmp/example_data Download a given dataset client . download ( '<workflow-dataset>' , target_directory = '/tmp/example_data' , revision = '<revision>' ) We will use this data as an example for the tutorial notebooks for each workflow. If you want to use for own dataset for the workflow, change the path accordingly. Directory organization workflow-array-ephys Click to expand details /tmp/example_data/ - subject6 - session1 - towersTask_g0_imec0 - towersTask_g0_t0_nidq.meta - towersTask_g0_t0.nidq.bin The example subject6/session1 data was recorded with SpikeGLX and processed with Kilosort2. element-array-ephys and workflow-array-ephys also support data recorded with OpenEphys. workflow-calcium-imaging Click to expand details /tmp/example_data/ - subject3/ - 210107_run00_orientation_8dir/ - run00_orientation_8dir_000_000.sbx - run00_orientation_8dir_000_000.mat - suite2p/ - combined - plane0 - plane1 - plane2 - plane3 - subject7/ - session1 - suite2p - plane0 The example subject3 data was recorded with Scanbox and processed with Suite2p. The example subject7 data was recorded with ScanImage and processed with Suite2p. element-calcium-imaging and workflow-calcium-imaging also support data processed with CaImAn. Directory structure and file naming convention \u00b6 The workflow presented here is designed to work with the directory structure and file naming convention as described below. workflow-array-ephys Click to expand details The ephys_root_data_dir is configurable in the dj_local_conf.json , under custom/ephys_root_data_dir variable. The subject directory names must match the identifiers of your subjects in the subjects.csv script ( ./user_data/subjects.csv ). The session directories can have any naming convention. Each session can have multiple probes, the probe directories must match the following naming convention: `*[0-9]` (where `[0-9]` is a one digit number specifying the probe number) Each probe directory should contain: One neuropixels meta file, with the following naming convention: *[0-9].ap.meta Potentially one Kilosort output folder <ephys_root_data_dir>/ \u2514\u2500\u2500\u2500<subject1>/ # Subject name in `subjects.csv` \u2502 \u2514\u2500\u2500\u2500<session0>/ # Session directory in `sessions.csv` \u2502 \u2502 \u2514\u2500\u2500\u2500imec0/ \u2502 \u2502 \u2502 \u2502 *imec0.ap.meta \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500ksdir/ \u2502 \u2502 \u2502 \u2502 spike_times.npy \u2502 \u2502 \u2502 \u2502 templates.npy \u2502 \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500imec1/ \u2502 \u2502 \u2502 *imec1.ap.meta \u2502 \u2502 \u2514\u2500\u2500\u2500ksdir/ \u2502 \u2502 \u2502 spike_times.npy \u2502 \u2502 \u2502 templates.npy \u2502 \u2502 \u2502 ... \u2502 \u2514\u2500\u2500\u2500<session1>/ \u2502 \u2502 \u2502 ... \u2514\u2500\u2500\u2500<subject2>/ \u2502 \u2502 ... workflow-calcium-imaging Click to expand details Note: the element-calcium-imaging is designed to accommodate multiple scans per session, however, in this particular workflow-calcium-imaging , we take the assumption that there is only one scan per session. The imaging_root_data_dir directory is configurable in the dj_local_conf.json , under the custom/imaging_root_data_dir variable The subject directory names must match the identifiers of your subjects in the subjects.csv script ( ./user_data/subjects.csv ). The session directories can have any naming convention Each session directory should contain: All .tif or .sbx files for the scan, with any naming convention One suite2p subfolder per session folder, containing the Suite2p analysis outputs One caiman subfolder per session folder, containing the CaImAn analysis output .hdf5 file, with any naming convention imaging_root_data_dir/ \u2514\u2500\u2500\u2500<subject1>/ # Subject name in `subjects.csv` \u2502 \u2514\u2500\u2500\u2500<session0>/ # Session directory in `sessions.csv` \u2502 \u2502 \u2502 scan_0001.tif \u2502 \u2502 \u2502 scan_0002.tif \u2502 \u2502 \u2502 scan_0003.tif \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500suite2p/ \u2502 \u2502 \u2502 ops1.npy \u2502 \u2502 \u2514\u2500\u2500\u2500plane0/ \u2502 \u2502 \u2502 \u2502 ops.npy \u2502 \u2502 \u2502 \u2502 spks.npy \u2502 \u2502 \u2502 \u2502 stat.npy \u2502 \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500plane1/ \u2502 \u2502 \u2502 ops.npy \u2502 \u2502 \u2502 spks.npy \u2502 \u2502 \u2502 stat.npy \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500caiman/ \u2502 \u2502 \u2502 analysis_results.hdf5 \u2502 \u2514\u2500\u2500\u2500<session1>/ # Session directory in `sessions.csv` \u2502 \u2502 \u2502 scan_0001.tif \u2502 \u2502 \u2502 scan_0002.tif \u2502 \u2502 \u2502 ... \u2514\u2500\u2500\u2500<subject2>/ # Subject name in `subjects.csv` \u2502 \u2502 ... Interacting with the DataJoint workflow \u00b6 Connect to the database and import tables from < relevant - workflow >. pipeline import * View the declared tables - workflow-array-ephys Click to expand details ```python subject.Subject() session.Session() ephys.ProbeInsertion() ephys.EphysRecording() ephys.Clustering() ephys.Clustering.Unit() ``` - workflow-calcium-imaging Click to expand details ```python subject.Subject() session.Session() scan.Scan() scan.ScanInfo() imaging.ProcessingParamSet() imaging.ProcessingTask() ``` </details> For an in depth explanation of how to run the workflows and explore the data, please refer to the following workflow specific Jupyter notebooks. + workflow-array-ephys Jupyter notebooks + workflow-calcium-imaging Jupyter notebooks DataJoint LabBook \u00b6 DataJoint LabBook is a graphical user interface to facilitate working with DataJoint tables. DataJoint LabBook Documentation , including prerequisites, installation, and running the application DataJoint LabBook GitHub Repository","title":"User Instructions"},{"location":"elements/user-instructions/#user-setup-instructions","text":"Instructions for workflows created with the DataJoint Elements The following document describes the steps to setup a development environment so that you can use the DataJoint Elements to build and run a workflow on your local machine. The DataJoint Elements can be combined together to create a workflow that matches your experimental setup. We have created example workflows (e.g. workflow-array-ephys , workflow-calcium-imaging ) for your reference. In this tutorial we will install these example DataJoint workflows. These instructions can be adapted for your custom DataJoint workflow. There are several ways to create a development environment. Here we will discuss one method in detail, and will highlight other methods along the way. If you have already set up certain components, feel free to skip those sections. You will need administrative privileges on your system for the following setup instructions.","title":"User setup instructions"},{"location":"elements/user-instructions/#system-architecture","text":"The above diagram describes the general components for a local DataJoint development environment.","title":"System architecture"},{"location":"elements/user-instructions/#install-an-integrated-development-environment","text":"DataJoint development and use can be done with a plain text editor in the terminal. However, an integrated development environment (IDE) can improve your experience. Several IDEs are available. In this setup example, we will use Microsoft's Visual Studio Code. Installation instructions here","title":"Install an integrated development environment"},{"location":"elements/user-instructions/#install-a-relational-database","text":"A key feature of DataJoint is the ability to connect with a database server from a scientific programming environment (i.e., Python or MATLAB) so that your experimental data can be stored in the database and downloaded from the database. There are several options if you would like to install a local relational database server. If using the Docker and Compose files that come with each workflow (e.g. workflow-calcium-imaging ), these are preconfigured with a Docker container that hosts a MySQL server. Docker image for MySQL server configured for use with DataJoint Install MariaDB server Alternatively, for the simplicity of this tutorial you can use the DataJoint tutorial database located at tutorial-db.datajoint.io which has already been configured. The credentials to log in to the tutorial database are the same as for DataJoint Accounts . Please note that the tutorial database should not be used for your experimental analysis as the storage is not persistent.","title":"Install a relational database"},{"location":"elements/user-instructions/#install-a-version-control-system","text":"Git is an open-source, distributed version control system for collaborating with software development. GitHub is a platform that hosts projects managed with Git. As the example DataJoint workflows are hosted on GitHub, we will use Git to clone (i.e., download) this repository. For your own DataJoint workflow development we recommended that you use Git and GitHub for collaboration. Many systems come preinstalled with Git. You can test if Git is already installed by typing git in a terminal window. If Git is not installed on your system, Install Git .","title":"Install a version control system"},{"location":"elements/user-instructions/#install-a-virtual-environment","text":"A virtual environment allows you to install the packages required for a specific project within an isolated environment on your computer. It is highly recommended (though not strictly required) to create a virtual environment to run the workflow. Conda and virtualenv are virtual environment managers and you can use either option. Below you will find instructions for conda. Miniconda is a minimal installer for conda. Follow the installer instructions for your operating system. You may need to add the Miniconda directory to the PATH environment variable First locate the Miniconda directory Then modify and run the following command export PATH = \"<absolute-path-to-miniconda-directory>/bin: $PATH \" Create a new conda environment conda create -n <environment_name> python = <version> Example command to create a conda environment conda create -n workflow-array-ephys python = 3 .8.11 Activate the conda environment conda activate <environment_name>","title":"Install a virtual environment"},{"location":"elements/user-instructions/#install-jupyter-notebook-packages","text":"Install the following, if you are using Jupyter Notebook. conda install jupyter ipykernel nb_conda_kernels Install the following, for dj.Diagram to render. conda install graphviz python-graphviz pydotplus","title":"Install Jupyter Notebook packages"},{"location":"elements/user-instructions/#clone-and-install-the-relevant-repository","text":"In a terminal window and change the directory to where you want to clone the repository cd ~/Projects Clone the relevant repository, often one of the workflows git clone https://github.com/datajoint/<repository> Change into the cloned directory cd <repository> From the root of the cloned repository directory. Note: the -e flag, which will will install this repository in editable mode, in case there's a need to modify the code (e.g. the workflow pipeline.py or paths.py scripts). If no such modification is required, using pip install . is sufficient. pip install -e . Install element-interface , which contains scripts to load data for many of our Elements, and all workflows pip install \"element-interface @ git+https://github.com/datajoint/element-interface\" Items specific to workflow-calcium-imaging Click to expand details element-interface can also be used to install packages used for reading acquired data (e.g., scanreader ) and running analyses (e.g., CaImAn ). Install element-interface with scanreader pip install \"element-interface[scanreader] @ git+https://github.com/datajoint/element-interface\" Install element-interface with sbxreader pip install \"element-interface[sbxreader] @ git+https://github.com/datajoint/element-interface\" Install element-interface with Suite2p pip install \"element-interface[suite2p] @ git+https://github.com/datajoint/element-interface\" Install element-interface with CaImAn requires two separate commands pip install \"element-interface[caiman_requirements] @ git+https://github.com/datajoint/element-interface\" pip install \"element-interface[caiman] @ git+https://github.com/datajoint/element-interface\" Example element-interface installation with multiple packages bash pip install \"element-interface[caiman_requirements] @ git+https://github.com/datajoint/element-interface\" pip install \"element-interface[scanreader,sbxreader,suite2p,caiman] @ git+https://github.com/datajoint/element-interface\"","title":"Clone and install the relevant repository"},{"location":"elements/user-instructions/#set-up-a-connection-to-the-database-server","text":"One way to set up a connection to the database server with DataJoint is to create a local configuration file (i.e., dj_local_conf.json ) at the root of the repository folder, with the following template: { \"database.host\" : \"<hostname>\" , \"database.user\" : \"<username>\" , \"database.password\" : \"<password>\" , \"loglevel\" : \"INFO\" , \"safemode\" : true , \"display.limit\" : 7 , \"display.width\" : 14 , \"display.show_tuple_count\" : true , \"custom\" : { \"database.prefix\" : \"<username_>\" } } Specify the database's hostname , username , and password . If using the Docker image for MySQL server configured for use with DataJoint then the hostname will be localhost . If using the tutorial database, the hostname will be tutorial-db.datajoint.io . And the username and password will be the credentials for your DataJoint account . Specify a database.prefix which will be the prefix for your schema names. For a local setup, it can be set as you see fit (e.g., neuro_ ). For the tutorial-db database, you will use your DataJoint username. Specific workflows will require additional information in the custom field, including paths to data directories, following the convention described in the directory structure section . If multiple root directories exist, include all in the relevant json array. + workflow-array-ephys Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"ephys_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details> + workflow-calcium-imaging Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"imaging_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details> + workflow-miniscope Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"miniscope_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details> + workflow-deeplabcut Click to expand ```json \"custom\": { \"database.prefix\": \"<username_>\", \"dlc_root_data_dir\": [\"Full path to root directory of raw data\", \"Full path to root directory of processed data\"] } ``` </details>","title":"Set up a connection to the database server"},{"location":"elements/user-instructions/#setup-complete","text":"At this point the setup of this workflow is complete.","title":"Setup complete"},{"location":"elements/user-instructions/#download-example-data","text":"We provide example data to use with the example DataJoint workflows. The data is hosted on DataJoint's Archive which is an AWS storage and can be download with djarchive-client . Install djarchive-client pip install git+https://github.com/datajoint/djarchive-client.git In your python interpreter, import the client import djarchive_client client = djarchive_client . client () Browse the available datasets list ( client . datasets ()) Each datasets has different versions associated with the version of the workflow package. Browse the revisions. python list(client.revisions()) Prepare a directory to store the download data, for example in /tmp mkdir /tmp/example_data Download a given dataset client . download ( '<workflow-dataset>' , target_directory = '/tmp/example_data' , revision = '<revision>' ) We will use this data as an example for the tutorial notebooks for each workflow. If you want to use for own dataset for the workflow, change the path accordingly. Directory organization workflow-array-ephys Click to expand details /tmp/example_data/ - subject6 - session1 - towersTask_g0_imec0 - towersTask_g0_t0_nidq.meta - towersTask_g0_t0.nidq.bin The example subject6/session1 data was recorded with SpikeGLX and processed with Kilosort2. element-array-ephys and workflow-array-ephys also support data recorded with OpenEphys. workflow-calcium-imaging Click to expand details /tmp/example_data/ - subject3/ - 210107_run00_orientation_8dir/ - run00_orientation_8dir_000_000.sbx - run00_orientation_8dir_000_000.mat - suite2p/ - combined - plane0 - plane1 - plane2 - plane3 - subject7/ - session1 - suite2p - plane0 The example subject3 data was recorded with Scanbox and processed with Suite2p. The example subject7 data was recorded with ScanImage and processed with Suite2p. element-calcium-imaging and workflow-calcium-imaging also support data processed with CaImAn.","title":"Download example data"},{"location":"elements/user-instructions/#directory-structure-and-file-naming-convention","text":"The workflow presented here is designed to work with the directory structure and file naming convention as described below. workflow-array-ephys Click to expand details The ephys_root_data_dir is configurable in the dj_local_conf.json , under custom/ephys_root_data_dir variable. The subject directory names must match the identifiers of your subjects in the subjects.csv script ( ./user_data/subjects.csv ). The session directories can have any naming convention. Each session can have multiple probes, the probe directories must match the following naming convention: `*[0-9]` (where `[0-9]` is a one digit number specifying the probe number) Each probe directory should contain: One neuropixels meta file, with the following naming convention: *[0-9].ap.meta Potentially one Kilosort output folder <ephys_root_data_dir>/ \u2514\u2500\u2500\u2500<subject1>/ # Subject name in `subjects.csv` \u2502 \u2514\u2500\u2500\u2500<session0>/ # Session directory in `sessions.csv` \u2502 \u2502 \u2514\u2500\u2500\u2500imec0/ \u2502 \u2502 \u2502 \u2502 *imec0.ap.meta \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500ksdir/ \u2502 \u2502 \u2502 \u2502 spike_times.npy \u2502 \u2502 \u2502 \u2502 templates.npy \u2502 \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500imec1/ \u2502 \u2502 \u2502 *imec1.ap.meta \u2502 \u2502 \u2514\u2500\u2500\u2500ksdir/ \u2502 \u2502 \u2502 spike_times.npy \u2502 \u2502 \u2502 templates.npy \u2502 \u2502 \u2502 ... \u2502 \u2514\u2500\u2500\u2500<session1>/ \u2502 \u2502 \u2502 ... \u2514\u2500\u2500\u2500<subject2>/ \u2502 \u2502 ... workflow-calcium-imaging Click to expand details Note: the element-calcium-imaging is designed to accommodate multiple scans per session, however, in this particular workflow-calcium-imaging , we take the assumption that there is only one scan per session. The imaging_root_data_dir directory is configurable in the dj_local_conf.json , under the custom/imaging_root_data_dir variable The subject directory names must match the identifiers of your subjects in the subjects.csv script ( ./user_data/subjects.csv ). The session directories can have any naming convention Each session directory should contain: All .tif or .sbx files for the scan, with any naming convention One suite2p subfolder per session folder, containing the Suite2p analysis outputs One caiman subfolder per session folder, containing the CaImAn analysis output .hdf5 file, with any naming convention imaging_root_data_dir/ \u2514\u2500\u2500\u2500<subject1>/ # Subject name in `subjects.csv` \u2502 \u2514\u2500\u2500\u2500<session0>/ # Session directory in `sessions.csv` \u2502 \u2502 \u2502 scan_0001.tif \u2502 \u2502 \u2502 scan_0002.tif \u2502 \u2502 \u2502 scan_0003.tif \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500suite2p/ \u2502 \u2502 \u2502 ops1.npy \u2502 \u2502 \u2514\u2500\u2500\u2500plane0/ \u2502 \u2502 \u2502 \u2502 ops.npy \u2502 \u2502 \u2502 \u2502 spks.npy \u2502 \u2502 \u2502 \u2502 stat.npy \u2502 \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500plane1/ \u2502 \u2502 \u2502 ops.npy \u2502 \u2502 \u2502 spks.npy \u2502 \u2502 \u2502 stat.npy \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2514\u2500\u2500\u2500caiman/ \u2502 \u2502 \u2502 analysis_results.hdf5 \u2502 \u2514\u2500\u2500\u2500<session1>/ # Session directory in `sessions.csv` \u2502 \u2502 \u2502 scan_0001.tif \u2502 \u2502 \u2502 scan_0002.tif \u2502 \u2502 \u2502 ... \u2514\u2500\u2500\u2500<subject2>/ # Subject name in `subjects.csv` \u2502 \u2502 ...","title":"Directory structure and file naming convention"},{"location":"elements/user-instructions/#interacting-with-the-datajoint-workflow","text":"Connect to the database and import tables from < relevant - workflow >. pipeline import * View the declared tables - workflow-array-ephys Click to expand details ```python subject.Subject() session.Session() ephys.ProbeInsertion() ephys.EphysRecording() ephys.Clustering() ephys.Clustering.Unit() ``` - workflow-calcium-imaging Click to expand details ```python subject.Subject() session.Session() scan.Scan() scan.ScanInfo() imaging.ProcessingParamSet() imaging.ProcessingTask() ``` </details> For an in depth explanation of how to run the workflows and explore the data, please refer to the following workflow specific Jupyter notebooks. + workflow-array-ephys Jupyter notebooks + workflow-calcium-imaging Jupyter notebooks","title":"Interacting with the DataJoint workflow"},{"location":"elements/user-instructions/#datajoint-labbook","text":"DataJoint LabBook is a graphical user interface to facilitate working with DataJoint tables. DataJoint LabBook Documentation , including prerequisites, installation, and running the application DataJoint LabBook GitHub Repository","title":"DataJoint LabBook"},{"location":"elements/management/adopt/","text":"Guidelines for Adoption \u00b6 You have several options for adopting DataJoint workflows for your own experiments. Adopt independently \u00b6 DataJoint Elements are designed for adoption by independent users with moderate software development skills, good understanding of DataJoint principles, and adequate IT expertise or support. If you have not yet used DataJoint, we recommend completing our online training tutorials or attending a workshop either online or in person. Interactive tutorials can be found on DataJoint CodeBook . Support from DataJoint \u00b6 Our team provides support to labs to adopt DataJoint workflows in their research. This includes: User training Developer training Data and computation hosting on your premises using your own cloud accounts fully managed cloud hosting by DataJoint Workflow execution configuration and automation optional fully managed service by DataJoint Interfaces for data entry, export and publishing These services may be subsidized by grant funding for qualified research groups.","title":"Adopt"},{"location":"elements/management/adopt/#guidelines-for-adoption","text":"You have several options for adopting DataJoint workflows for your own experiments.","title":"Guidelines for Adoption"},{"location":"elements/management/adopt/#adopt-independently","text":"DataJoint Elements are designed for adoption by independent users with moderate software development skills, good understanding of DataJoint principles, and adequate IT expertise or support. If you have not yet used DataJoint, we recommend completing our online training tutorials or attending a workshop either online or in person. Interactive tutorials can be found on DataJoint CodeBook .","title":"Adopt independently"},{"location":"elements/management/adopt/#support-from-datajoint","text":"Our team provides support to labs to adopt DataJoint workflows in their research. This includes: User training Developer training Data and computation hosting on your premises using your own cloud accounts fully managed cloud hosting by DataJoint Workflow execution configuration and automation optional fully managed service by DataJoint Interfaces for data entry, export and publishing These services may be subsidized by grant funding for qualified research groups.","title":"Support from DataJoint"},{"location":"elements/management/governance/","text":"Project Governance \u00b6 Funding \u00b6 This Resource is supported by the National Institute Of Neurological Disorders And Stroke of the National Institutes of Health under Award Number U24NS116470. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. Scientific Steering Group \u00b6 The project oversight and guidance is provided by the Scientific Steering Group comprising Mackenzie Mathis (EPFL) John Cunningham (Columbia U) Carlos Brody (Princeton U) Karel Svoboda (Allen Institute) Nick Steinmetz (U of Washington) Loren Frank (UCSF)","title":"Governance"},{"location":"elements/management/governance/#project-governance","text":"","title":"Project Governance"},{"location":"elements/management/governance/#funding","text":"This Resource is supported by the National Institute Of Neurological Disorders And Stroke of the National Institutes of Health under Award Number U24NS116470. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.","title":"Funding"},{"location":"elements/management/governance/#scientific-steering-group","text":"The project oversight and guidance is provided by the Scientific Steering Group comprising Mackenzie Mathis (EPFL) John Cunningham (Columbia U) Carlos Brody (Princeton U) Karel Svoboda (Allen Institute) Nick Steinmetz (U of Washington) Loren Frank (UCSF)","title":"Scientific Steering Group"},{"location":"elements/management/outreach/","text":"Outreach Plan \u00b6 Broad engagement with the neuroscience community is necessary for the optimization, integration, and adoption of the Resource components. We conduct five types of outreach activities that require different approaches: 1. Precursor Projects \u00b6 Our Selection Process requires a \"Precursor Project\" for any new experiment modality to be included in DataJoint Elements. A precursor project is a project that develops a DataJoint pipeline for its own experiments either independently or in collaboration with our team. We reach out to teams who develop DataJoint pipelines for new experiment paradigms and modalities to identify essential design motifs, analysis tools, and related tools and interfaces. We interview the core team to learn about their collaborative culture, practices, and procedures. We jointly review their open-source code and their plans for dissemination. In many cases, our team already collaborates with such teams through our other projects and we have a good understanding of their process. As we develop a new Element to support the new modality, we remain in contact with the team to include their contribution, solicit feedback, and evaluate design tradeoffs. When the new Element is released, a full attribution is given to the Precursor Project. Rationale: The Resource does not aim to develop fundamentally new solutions for neurophysiology data acquisition and analysis. Rather it aims to systematize and disseminate existing open-source tools proven in leading research projects. 2. Tool Developers \u00b6 DataJoint pipelines rely on analysis tools, atlases, data standards, archives and catalogs, and other neuroinformatics resources developed and maintained by the broader scientific community. To ensure sustainability of the Resource, we reach out to the tool developer to establish joint sustainability roadmaps. 3. Dissemination \u00b6 We conduct activities to disseminate Resource components for adoption in diverse neuroscience labs. These activities include A central website for the Resource. Conference talks, presentations, and workshops Publications in peer-reviewed journals White papers posted on internet resources and websites On-site workshops by invitation Remote workshops and webinars Online interactive tutorials hosted on DataJoint CodeBook . 4. Census \u00b6 In order to measure the effectiveness of the Resource, we conduct several activities to estimate the adoption and use of the Resource components: A citation mechanism for individual components of the Resource. Resource RRID DataJoint RRID:SCR_014543 DataJoint Elements RRID:SCR_021894 Collect summary statistics of the number of downloads and repository forking. A register for self-reporting for component adoption and use (see DataJoint Census ).","title":"Outreach"},{"location":"elements/management/outreach/#outreach-plan","text":"Broad engagement with the neuroscience community is necessary for the optimization, integration, and adoption of the Resource components. We conduct five types of outreach activities that require different approaches:","title":"Outreach Plan"},{"location":"elements/management/outreach/#1-precursor-projects","text":"Our Selection Process requires a \"Precursor Project\" for any new experiment modality to be included in DataJoint Elements. A precursor project is a project that develops a DataJoint pipeline for its own experiments either independently or in collaboration with our team. We reach out to teams who develop DataJoint pipelines for new experiment paradigms and modalities to identify essential design motifs, analysis tools, and related tools and interfaces. We interview the core team to learn about their collaborative culture, practices, and procedures. We jointly review their open-source code and their plans for dissemination. In many cases, our team already collaborates with such teams through our other projects and we have a good understanding of their process. As we develop a new Element to support the new modality, we remain in contact with the team to include their contribution, solicit feedback, and evaluate design tradeoffs. When the new Element is released, a full attribution is given to the Precursor Project. Rationale: The Resource does not aim to develop fundamentally new solutions for neurophysiology data acquisition and analysis. Rather it aims to systematize and disseminate existing open-source tools proven in leading research projects.","title":"1. Precursor Projects"},{"location":"elements/management/outreach/#2-tool-developers","text":"DataJoint pipelines rely on analysis tools, atlases, data standards, archives and catalogs, and other neuroinformatics resources developed and maintained by the broader scientific community. To ensure sustainability of the Resource, we reach out to the tool developer to establish joint sustainability roadmaps.","title":"2. Tool Developers"},{"location":"elements/management/outreach/#3-dissemination","text":"We conduct activities to disseminate Resource components for adoption in diverse neuroscience labs. These activities include A central website for the Resource. Conference talks, presentations, and workshops Publications in peer-reviewed journals White papers posted on internet resources and websites On-site workshops by invitation Remote workshops and webinars Online interactive tutorials hosted on DataJoint CodeBook .","title":"3. Dissemination"},{"location":"elements/management/outreach/#4-census","text":"In order to measure the effectiveness of the Resource, we conduct several activities to estimate the adoption and use of the Resource components: A citation mechanism for individual components of the Resource. Resource RRID DataJoint RRID:SCR_014543 DataJoint Elements RRID:SCR_021894 Collect summary statistics of the number of downloads and repository forking. A register for self-reporting for component adoption and use (see DataJoint Census ).","title":"4. Census"},{"location":"elements/management/plan/","text":"Management Plan \u00b6 DataJoint Elements has established a Resource Management Plan to select projects for development, to assure quality, and to disseminate its output as summarized in the figure below: The following sections provide detailed information. Team Project Governance Project Selection Process Quality Assurance Contribution Guideline Outreach Plan Licenses and User Agreements","title":"Plan"},{"location":"elements/management/plan/#management-plan","text":"DataJoint Elements has established a Resource Management Plan to select projects for development, to assure quality, and to disseminate its output as summarized in the figure below: The following sections provide detailed information. Team Project Governance Project Selection Process Quality Assurance Contribution Guideline Outreach Plan Licenses and User Agreements","title":"Management Plan"},{"location":"elements/management/quality-assurance/","text":"Quality Assurance \u00b6 DataJoint and DataJoint Elements serve as a framework and starting points for numerous new projects, setting the standard of quality for data architecture and software design. To ensure higher quality, the following policies have been adopted into the software development lifecycle (SDLC). Coding Standards \u00b6 When writing code, the following principles should be observed. Style : Code shall be written for clear readability. Uniform and clear naming conventions, module structure, and formatting requirements shall be established across all components of the project. Python's PEP8 standard offers clear guidance to this regard which can similarly be applied to all languages. Python code is formatted with the black code formatter. Line length should be a maximum of 88 characters. Maintenance Overhead : Code base size should be noted to prevent large, unnecessarily complex solutions from being introduced. The idea is that the larger the code base, the more there is to review and maintain. Therefore, we should aim to find a compromise where we can keep the code base from becoming too large without adding convoluted complexity. Performance : Performance drawbacks should be avoided, controlled, or, at least, be properly monitored and justified. For instance: memory management, garbage collection, disk reads/writes, and processing overhead should be regarded to ensure that an efficient solution is achieved. Automated Testing \u00b6 All components and their revisions must include appropriate automated software testing to be considered for release. The core framework must undergo thorough performance evaluation and comprehensive integration testing. Generally, this includes tests related to: Syntax : Verify that the code base does not contain any syntax errors and will run or compile successfully. Unit & Integration : Verify that low-level, method-specific tests (unit tests) and any tests related coordinated interface between methods (integration tests) pass successfully. Typically, when bugs are patched or features are introduced, unit and integration tests are added to ensure that the use-case intended to be satisfied is accounted for. This helps us prevent any regression in functionality. Style : Verify that the code base adheres to style guides for optimal readability. Code Coverage : Verify that the code base has similar or better code coverage than the last run. Code Reviews \u00b6 When introducing new code to the code base, the following will be required for acceptance by DataJoint core team into the main code repository. Independence : Proposed changes should not directly alter the code base in the review process. New changes should be applied separately on a copy of the code base and proposed for review by the DataJoint core team. For example, apply changes on a GitHub fork and open a pull request targeting the main branch once ready for review. Etiquette : An author who has requested for a code for review should not accept and merge their own code to the code base. A reviewer should not commit any suggestions directly to the authors proposed changes but rather should allow the author to review. Coding Standards : Ensure the above coding standards are respected. Summary : A description should be included that summarizes and highlights the notable changes that are being proposed. Issue Reference : Any bugs or feature requests that have been filed in the issue tracker that would be resolved by acceptance should be properly linked and referenced. Satisfy Automated Tests : All automated tests associated with the project will be verified to be successful prior to acceptance. Documentation : Documentation should be included to reflect any new feature or behavior introduced. Release Notes : Include necessary updates to the release notes or change log to capture a summary of the patched bugs and new feature introduction. Proper linking should be maintained to associated tickets in issue tracker and reviews. Release Process \u00b6 Upon satisfactory adherence to the above Coding Standards, Automated Testing, and Code Reviews: The package version will be incremented following the standard definition of Semantic Versioning with a Major.Minor.Patch number. Updates will be merged into the base repository main branch. A new release will be made on PyPI. For external research teams that reach out to us, we will provide engineering support to help users adopt the updated software, collect feedback, and resolve issues following the processes described in the section below. If the updates require changes in the design of the database schema or formats, a process for data migration will be provided upon request. User Feedback & Issue Tracking \u00b6 All components will be organized in GitHub repositories with guidelines for contribution, feedback, and issue submission to the issue tracker. For more information on the general policy around issue filing, tracking, and escalation, see the DataJoint Open-Source Contribute policy. For research groups that reach out to us, our team will work closely to collect feedback and resolve issues. Typically issues will be prioritized based on their criticality and impact. If new feature requirements become apparent, this may trigger the creation of a separate workflow or a major revision of an existing workflow.","title":"Quality Assurance"},{"location":"elements/management/quality-assurance/#quality-assurance","text":"DataJoint and DataJoint Elements serve as a framework and starting points for numerous new projects, setting the standard of quality for data architecture and software design. To ensure higher quality, the following policies have been adopted into the software development lifecycle (SDLC).","title":"Quality Assurance"},{"location":"elements/management/quality-assurance/#coding-standards","text":"When writing code, the following principles should be observed. Style : Code shall be written for clear readability. Uniform and clear naming conventions, module structure, and formatting requirements shall be established across all components of the project. Python's PEP8 standard offers clear guidance to this regard which can similarly be applied to all languages. Python code is formatted with the black code formatter. Line length should be a maximum of 88 characters. Maintenance Overhead : Code base size should be noted to prevent large, unnecessarily complex solutions from being introduced. The idea is that the larger the code base, the more there is to review and maintain. Therefore, we should aim to find a compromise where we can keep the code base from becoming too large without adding convoluted complexity. Performance : Performance drawbacks should be avoided, controlled, or, at least, be properly monitored and justified. For instance: memory management, garbage collection, disk reads/writes, and processing overhead should be regarded to ensure that an efficient solution is achieved.","title":"Coding Standards"},{"location":"elements/management/quality-assurance/#automated-testing","text":"All components and their revisions must include appropriate automated software testing to be considered for release. The core framework must undergo thorough performance evaluation and comprehensive integration testing. Generally, this includes tests related to: Syntax : Verify that the code base does not contain any syntax errors and will run or compile successfully. Unit & Integration : Verify that low-level, method-specific tests (unit tests) and any tests related coordinated interface between methods (integration tests) pass successfully. Typically, when bugs are patched or features are introduced, unit and integration tests are added to ensure that the use-case intended to be satisfied is accounted for. This helps us prevent any regression in functionality. Style : Verify that the code base adheres to style guides for optimal readability. Code Coverage : Verify that the code base has similar or better code coverage than the last run.","title":"Automated Testing"},{"location":"elements/management/quality-assurance/#code-reviews","text":"When introducing new code to the code base, the following will be required for acceptance by DataJoint core team into the main code repository. Independence : Proposed changes should not directly alter the code base in the review process. New changes should be applied separately on a copy of the code base and proposed for review by the DataJoint core team. For example, apply changes on a GitHub fork and open a pull request targeting the main branch once ready for review. Etiquette : An author who has requested for a code for review should not accept and merge their own code to the code base. A reviewer should not commit any suggestions directly to the authors proposed changes but rather should allow the author to review. Coding Standards : Ensure the above coding standards are respected. Summary : A description should be included that summarizes and highlights the notable changes that are being proposed. Issue Reference : Any bugs or feature requests that have been filed in the issue tracker that would be resolved by acceptance should be properly linked and referenced. Satisfy Automated Tests : All automated tests associated with the project will be verified to be successful prior to acceptance. Documentation : Documentation should be included to reflect any new feature or behavior introduced. Release Notes : Include necessary updates to the release notes or change log to capture a summary of the patched bugs and new feature introduction. Proper linking should be maintained to associated tickets in issue tracker and reviews.","title":"Code Reviews"},{"location":"elements/management/quality-assurance/#release-process","text":"Upon satisfactory adherence to the above Coding Standards, Automated Testing, and Code Reviews: The package version will be incremented following the standard definition of Semantic Versioning with a Major.Minor.Patch number. Updates will be merged into the base repository main branch. A new release will be made on PyPI. For external research teams that reach out to us, we will provide engineering support to help users adopt the updated software, collect feedback, and resolve issues following the processes described in the section below. If the updates require changes in the design of the database schema or formats, a process for data migration will be provided upon request.","title":"Release Process"},{"location":"elements/management/quality-assurance/#user-feedback-issue-tracking","text":"All components will be organized in GitHub repositories with guidelines for contribution, feedback, and issue submission to the issue tracker. For more information on the general policy around issue filing, tracking, and escalation, see the DataJoint Open-Source Contribute policy. For research groups that reach out to us, our team will work closely to collect feedback and resolve issues. Typically issues will be prioritized based on their criticality and impact. If new feature requirements become apparent, this may trigger the creation of a separate workflow or a major revision of an existing workflow.","title":"User Feedback &amp; Issue Tracking"},{"location":"elements/management/selection/","text":"Project Selection Process \u00b6 The project milestones are set annually by the team under the stewardship of the NIH programmatic staff and with the guidance of the project's Scientific Steering Group We have adopted the following general criteria for selecting and accepting new projects to be included in the Resource. Open Precursor Projects At least one open-source DataJoint-based precursor project must exist for any new experiment modality to be accepted for support as part of the Resource. The precursor project team must be open to interviews to describe in detail their process for the experiment workflow, tools, and interfaces. The precursor projects must provide sample data for testing during development and for tutorials. The precursor projects will be acknowledged in the development of the component. Rationale: This Resource does not aim to develop fundamentally new solutions for neurophysiology data acquisition and analysis. Rather it seeks to systematize and disseminate existing open-source tools proven in leading research projects. Impact New components proposed for support in the project must be shown to be in demand by a substantial population or research groups, on the order of 100+ labs globally. Sustainability For all third-party tools or resources included in the proposed component, their long-term maintenance roadmap must be established. When possible, we will contact the developer team and work with them to establish a sustainability roadmap. If no such roadmap can be established, alternative tools and resources must be identified as replacement.","title":"Selection"},{"location":"elements/management/selection/#project-selection-process","text":"The project milestones are set annually by the team under the stewardship of the NIH programmatic staff and with the guidance of the project's Scientific Steering Group We have adopted the following general criteria for selecting and accepting new projects to be included in the Resource. Open Precursor Projects At least one open-source DataJoint-based precursor project must exist for any new experiment modality to be accepted for support as part of the Resource. The precursor project team must be open to interviews to describe in detail their process for the experiment workflow, tools, and interfaces. The precursor projects must provide sample data for testing during development and for tutorials. The precursor projects will be acknowledged in the development of the component. Rationale: This Resource does not aim to develop fundamentally new solutions for neurophysiology data acquisition and analysis. Rather it seeks to systematize and disseminate existing open-source tools proven in leading research projects. Impact New components proposed for support in the project must be shown to be in demand by a substantial population or research groups, on the order of 100+ labs globally. Sustainability For all third-party tools or resources included in the proposed component, their long-term maintenance roadmap must be established. When possible, we will contact the developer team and work with them to establish a sustainability roadmap. If no such roadmap can be established, alternative tools and resources must be identified as replacement.","title":"Project Selection Process"},{"location":"elements/management/team/","text":"Team \u00b6 The project is performed by DataJoint with Dimitri Yatsenko as Principal Investigator. Scientists \u00b6 Dimitri Yatsenko - PI Thinh Nguyen - Data Scientist Kabilar Gunalan - Data Scientist Joseph Burling - Data Scientist Chris Brozdowski - Data Scientist Tolga Dincer - Data Scientist Sid Hulyalkar - Data Scientist Jaerong Ahn - Data Scientist Kushal Bakshi - Data Scientist Engineers \u00b6 Raphael Guzman - Software Engineer Drew Yang - Data Systems Engineer Jeroen Verswijver - Software Engineer Adib Baji - Software Engineer Timothy Chandler - Data Systems Engineer Chetana Pitani - Software Engineer Past contributors \u00b6 Edgar Y. Walker - System architect, Data Scientist, Project Manager (from project start to Jan, 2021) Andreas S. Tolias - Grant proposal contributor Jacob Reimer - Grant proposal contributor Shan Shen - Data Scientist Maho Sasaki - Software Engineer Daniel Sitonic - Software Engineer Christopher Turner - Data Systems Engineer David Godinez - Data Engineer Geetika Singh - Data Engineer Carlos Ortiz - Software Engineer The first-person pronouns \"we\" and \"our\" in these documents refer to those listed above. External contributors \u00b6 The principal components of the Resource are developed and distributed as open-source projects and external contributions are welcome. We have adopted a Contribution Guide for DataJoint, DataJoint Elements, and related open-source tools.","title":"Team"},{"location":"elements/management/team/#team","text":"The project is performed by DataJoint with Dimitri Yatsenko as Principal Investigator.","title":"Team"},{"location":"elements/management/team/#scientists","text":"Dimitri Yatsenko - PI Thinh Nguyen - Data Scientist Kabilar Gunalan - Data Scientist Joseph Burling - Data Scientist Chris Brozdowski - Data Scientist Tolga Dincer - Data Scientist Sid Hulyalkar - Data Scientist Jaerong Ahn - Data Scientist Kushal Bakshi - Data Scientist","title":"Scientists"},{"location":"elements/management/team/#engineers","text":"Raphael Guzman - Software Engineer Drew Yang - Data Systems Engineer Jeroen Verswijver - Software Engineer Adib Baji - Software Engineer Timothy Chandler - Data Systems Engineer Chetana Pitani - Software Engineer","title":"Engineers"},{"location":"elements/management/team/#past-contributors","text":"Edgar Y. Walker - System architect, Data Scientist, Project Manager (from project start to Jan, 2021) Andreas S. Tolias - Grant proposal contributor Jacob Reimer - Grant proposal contributor Shan Shen - Data Scientist Maho Sasaki - Software Engineer Daniel Sitonic - Software Engineer Christopher Turner - Data Systems Engineer David Godinez - Data Engineer Geetika Singh - Data Engineer Carlos Ortiz - Software Engineer The first-person pronouns \"we\" and \"our\" in these documents refer to those listed above.","title":"Past contributors"},{"location":"elements/management/team/#external-contributors","text":"The principal components of the Resource are developed and distributed as open-source projects and external contributions are welcome. We have adopted a Contribution Guide for DataJoint, DataJoint Elements, and related open-source tools.","title":"External contributors"}]}